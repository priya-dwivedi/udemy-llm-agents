{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic RAG with Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![agentic-rag](images/agentic-rag.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "import pprint\n",
    "##to load credentials\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") ## Put your OpenAI API key here\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\") ## Put your Tavily Search API key here\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\") ## Put your Langsmith API key here\n",
    "os.environ[\"LANGCHAIN_HUB_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\") ## Put your Langsmith API key here\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = 'true' ## Set this as True\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = 'https://api.smith.langchain.com/' ## Set this as: https://api.smith.langchain.com/\n",
    "os.environ[\"LANGCHAIN_HUB_API_URL\"] = 'https://api.hub.langchain.com' ## Set this as : https://api.hub.langchain.com\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = 'llm-agents'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Databases for the Query Router"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults(max_results=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.morningstar.com/markets/when-will-fed-start-cutting-interest-rates',\n",
       "  'content': 'At many points in the past 10 years (when the Fed first started issuing multiyear projections for the fed-funds rate), the Fed has veered from its initial forecasts owing to shifts in the data.\\n Then, starting around the beginning of 2024 (we expect in the first meeting in March 2024), we expect the Fed to begin cutting the fed-funds rate.\\n U.S. Interest-Rate Forecast: What We See for the Future\\nIn the short run, our interest-rate forecast is centered on the Fed and its attempt to smooth out economic cycles. Because the yield curve has inverted so much, the Fed has been forced to hike the federal-funds rate more than it would have otherwise in order to sufficiently cool off the economy.\\n When the economy is overheated (the output gap is positive and inflation is high), as today, then the Fed seeks to hike interest rates to slow growth.\\n'},\n",
       " {'url': 'https://apnews.com/article/federal-reserve-rate-cuts-inflation-spending-b85c813418a1d00cfcf0391e9441ce02',\n",
       "  'content': \"The Fed has pushed its key rate to a 23-year high of 5.3% in an effort to bring down inflation, which peaked at 9.1% in June 2022. Yet despite those sharp increases, Americans, on average, spent just 9.8% of their after-tax income paying interest and principal on their debts in last year's fourth quarter. Two years earlier â€” before the Fed ...\"},\n",
       " {'url': 'https://www.cnn.com/2024/06/12/economy/june-fed-decision/index.html',\n",
       "  'content': 'The Fed has kept interest rates at a 23-year high for nearly a year, after kicking off an aggressive rate-hiking campaign in March 2022. Central bankers are waiting for more evidence that ...'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_results = web_search_tool.invoke({\"query\": \"when will interest rates fall?\"})\n",
    "web_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arxiv Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Published: 2024-06-09\\nTitle: RATT: A Thought Structure for Coherent and Correct LLM Reasoning\\nAuthors: Jinghan Zhang, Xiting Wang, Weijieying Ren, Lu Jiang, Dongjie Wang, Kunpeng Liu\\nSummary: Large Language Models (LLMs) gain substantial reasoning and decision-making\\ncapabilities from thought structures. However, existing methods such as Tree of\\nThought and Retrieval Augmented Thoughts often fall short in complex tasks due\\nto the limitations of insufficient local retrieval of factual knowledge and\\ninadequate global selection of strategies. These limitations make it\\nchallenging for these methods to balance factual accuracy and comprehensive\\nlogical optimization effectively. To address these limitations, we introduce\\nthe Retrieval Augmented Thought Tree (RATT), a novel thought structure that\\nconsiders both overall logical soundness and factual correctness at each step\\nof the thinking process. Specifically, at every point of a thought branch, RATT\\nperforms planning and lookahead to explore and evaluate multiple potential\\nreasoning steps, and integrate the fact-checking ability of Retrieval-Augmented\\nGeneration (RAG) with LLM\\'s ability to assess overall strategy. Through this\\ncombination of factual knowledge and strategic feasibility, the RATT adjusts\\nand integrates the thought tree structure to search for the most promising\\nbranches within the search space. This thought structure significantly enhances\\nthe model\\'s coherence in logical inference and efficiency in decision-making,\\nand thus increases the limit of the capacity of LLM to generate reliable\\ninferences and decisions based on thought structures. A broad range of\\nexperiments on different types of tasks showcases that the RATT structure\\nsignificantly outperforms existing methods in factual correctness and logical\\ncoherence.\\n\\nPublished: 2024-02-23\\nTitle: Everything of Thoughts: Defying the Law of Penrose Triangle for Thought Generation\\nAuthors: Ruomeng Ding, Chaoyun Zhang, Lu Wang, Yong Xu, Minghua Ma, Wei Zhang, Si Qin, Saravan Rajmohan, Qingwei Lin, Dongmei Zhang\\nSummary: Recent advancements in Large Language Models (LLMs) have revolutionized\\ndecision-making by breaking down complex problems into more manageable language\\nsequences referred to as \"thoughts\". An effective thought design should\\nconsider three key perspectives: performance, efficiency, and flexibility.\\nHowever, existing thought can at most exhibit two of these attributes. To\\naddress these limitations, we introduce a novel thought prompting approach\\ncalled \"Everything of Thoughts\" (XoT) to defy the law of \"Penrose triangle of\\nexisting thought paradigms. XoT leverages pretrained reinforcement learning and\\nMonte Carlo Tree Search (MCTS) to incorporate external domain knowledge into\\nthoughts, thereby enhancing LLMs\\' capabilities and enabling them to generalize\\nto unseen problems efficiently. Through the utilization of the MCTS-LLM\\ncollaborative thought revision framework, this approach autonomously produces\\nhigh-quality comprehensive cognitive mappings with minimal LLM interactions.\\nAdditionally, XoT empowers LLMs to engage in unconstrained thinking, allowing\\nfor flexible cognitive mappings for problems with multiple solutions. We\\nevaluate XoT on several challenging multi-solution problem-solving tasks,\\nincluding Game of 24, 8-Puzzle, and Pocket Cube. Our results demonstrate that\\nXoT significantly outperforms existing approaches. Notably, XoT can yield\\nmultiple solutions with just one LLM call, showcasing its remarkable\\nproficiency in addressing complex problems across diverse domains.\\n\\nPublished: 2023-09-14\\nTitle: Tree of Uncertain Thoughts Reasoning for Large Language Models\\nAuthors: Shentong Mo, Miao Xin\\nSummary: While the recently introduced Tree of Thoughts (ToT) has heralded\\nadvancements in allowing Large Language Models (LLMs) to reason through\\nforesight and backtracking for global decision-making, it has overlooked the\\ninherent local uncertainties in intermediate decision points or \"thoughts\".\\nThese local uncertainties, intrinsic to LLMs given their potential for diverse\\nresponses, remain a significant concern in the reasoning process. Addressing\\nthis pivotal gap, we introduce the Tree of Uncertain Thoughts (TouT) - a\\nreasoning framework tailored for LLMs. Our TouT effectively leverages Monte\\nCarlo Dropout to quantify uncertainty scores associated with LLMs\\' diverse\\nlocal responses at these intermediate steps. By marrying this local uncertainty\\nquantification with global search algorithms, TouT enhances the model\\'s\\nprecision in response generation. We substantiate our approach with rigorous\\nexperiments on two demanding planning tasks: Game of 24 and Mini Crosswords.\\nThe empirical evidence underscores TouT\\'s superiority over both ToT and\\nchain-of-thought prompting methods.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities.arxiv import ArxivAPIWrapper\n",
    "arxiv = ArxivAPIWrapper(\n",
    "    top_k_results = 3,\n",
    "    ARXIV_MAX_QUERY_LENGTH = 300,\n",
    "    load_max_docs = 3,\n",
    "    load_all_available_meta = False,\n",
    "    doc_content_chars_max = 40000\n",
    ")\n",
    "arxiv.run(\"tree of thought llm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Private Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have: 64 pages\n",
      "We have: 126 chunks\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "loader = PyPDFLoader(\"data/recipes.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "print(f\"We have: {len(pages)} pages\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(pages)\n",
    "print(f\"We have: {len(doc_splits)} chunks\")\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "recipe_retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='2. Mix the vegetables with lentils and leave \\nto boil for 20 minutes.\\n3. Grind lentils, carrots and onion in the \\nblender. \\n4. Add the remaining ingredients to the soup \\nand return to the heat to boil for a while. \\n5. Serve the soup and garnish with parsley.\\nPreferred for\\nRamadan', metadata={'page': 3, 'source': 'data/recipes.pdf'}), Document(page_content='1 teaspoon of ginger \\n1 clove garlic \\n1 teaspoon of cumin   \\n1 tablespoon of tomato paste 4 cups of water \\n1 tablespoon soft coriander\\na pinch of turmeric\\na pinch of salt\\nPreparation : \\n1.  Wash vegetables and chop finely.2.  Sprinkle the canola oil in the pot then add onions, garlic, ginger and stir until they wilt. \\n3.  Add vegetables to pot, starting with potatoes, carrots, celery, pumpkin, zucchini and tomato. \\n4.  Mix the vegetables and sprinkle salt, spices, tomato paste and add water then leave on the \\nheat for half an hour. \\n5.  Sprinkle coriander on hot the soup and serve.Vegetable Soup\\nPreferred for\\nRamadan', metadata={'page': 4, 'source': 'data/recipes.pdf'}), Document(page_content='over medium-low heat.\\n2. Add onion and cook, stirring frequently, until onion \\nis very limp (about 10 minutes), taking care to not \\nlet the onion brown.\\n3. Add thyme, oregano, tomatoes with their juice,     and chicken broth. Bring to a boil; reduce heat        \\nto low and simmer, partially cover for 20 minutes.\\n4. Taste soup, add salt and pepper.\\n5. Stir in evaporated milk and heat through.\\n Do not let mixture actually boil.\\nCream of Tomato Soup', metadata={'page': 2, 'source': 'data/recipes.pdf'}), Document(page_content='4. When boiling, add spices, cover the pot and leave the mixture over low heat for 40 minutes. \\n5. Put all 4 slices toasted bread in clay bowl, add 2 tablespoons of cheese and 2 serving spoons of hot soup \\nin each bowl. \\n6. Put the bowls in the preheated oven at (250Âº) until content becomes brown.\\n7. Serve hot. Preferred for\\nRamadan', metadata={'page': 6, 'source': 'data/recipes.pdf'})]\n"
     ]
    }
   ],
   "source": [
    "docs = recipe_retriever.invoke(\"How do I make a lentil soup\")\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Router"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use semantic routing for fast routing of queries\n",
    "\n",
    "Learn more here: https://github.com/aurelio-labs/semantic-router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pdwivedi/miniconda3/envs/llm_agents/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from semantic_router import Route\n",
    "\n",
    "# we could use this as a guide for our chatbot to avoid political conversations\n",
    "recipes = Route(\n",
    "    name=\"recipes\",\n",
    "    utterances = [\n",
    "    \"How do I make lentil soup?\",\n",
    "    \"Share recipe for chicken soup\",\n",
    "    \"Do you have any salad recipes?\",\n",
    "    \"How do I make falafel?\"\n",
    "    ])\n",
    "\n",
    "ai = Route(\n",
    "    name=\"ai\",\n",
    "    utterances = [\n",
    "    \"What is tree of thought prompting?\",\n",
    "    \"Why is dropout using in neural networks?\",\n",
    "    \"How was Mistral model trained?\",\n",
    "    \"Tell me about RLHF\"\n",
    "    ])\n",
    "\n",
    "chitchat = Route(\n",
    "    name=\"chitchat\",\n",
    "    utterances=[\n",
    "        \"how's the weather today?\",\n",
    "        \"how are things going?\",\n",
    "        \"plans for the weekend\"\n",
    "    ],\n",
    ")\n",
    "\n",
    "# we place both of our decisions together into single list\n",
    "routes = [recipes, ai, chitchat]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-06-15 08:21:41 INFO semantic_router.utils.logger local\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from semantic_router.encoders import OpenAIEncoder\n",
    "encoder = OpenAIEncoder()\n",
    "\n",
    "from semantic_router.layer import RouteLayer\n",
    "rl = RouteLayer(encoder=encoder, routes=routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recipes\n"
     ]
    }
   ],
   "source": [
    "print(rl(\"How do I make onion soup?\").name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai\n"
     ]
    }
   ],
   "source": [
    "print(rl(\"What is chain of thought prompting?\").name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(rl(\"how do I go from NY to LA?\").name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Grader or document grader\n",
    "<i>This module will grade the quality of retrieved documents </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from together_llm import TogetherLLM\n",
    "\n",
    "\n",
    "llm_grader = TogetherLLM(model='meta-llama/Llama-3-8b-chat-hf', temperature=0.2, max_tokens=4)\n",
    "\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n",
    "    Only answer with the binary score as yes or no. I don't need explanation\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | llm_grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pdwivedi/miniconda3/envs/llm_agents/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "question = \"lentil soup recipe\"\n",
    "docs = recipe_retriever.get_relevant_documents(question)\n",
    "doc_txt = docs[1].page_content + docs[2].page_content + docs[3].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To make lentil soup, you need to put lentils, carrots, onion, and water in a pot and place it on high heat until boiling, then reduce the heat. Mix the vegetables with lentils and let it boil for 20 minutes. Grind lentils, carrots, and onion in a blender. Add the remaining ingredients to the soup and return it to the heat to boil for a while. Serve the soup and garnish with parsley.\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Prompt\n",
    "system_prompt = '''You are an assistant for question-answering tasks. Use the following pieces of retrieved context to \n",
    "answer the question. If you don't know the answer, just say that you don't know.\n",
    ".\\nQuestion: {question} \\nContext: {context} \\nAnswer:\n",
    "'''\n",
    "\n",
    "generate_answer_prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"], template=system_prompt)\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Chain\n",
    "rag_chain = generate_answer_prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the flow using Langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Agentic-RAG-block](images/agentic-rag-block.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: Question from the user\n",
    "        route: Route chosen by the Query Router\n",
    "        documents: list of documents from either RAG, Arxiv or websearch\n",
    "        score: document relevance score\n",
    "        answer: final response to user's question\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    route: str\n",
    "    documents: str\n",
    "    score: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Graph Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_router(state):\n",
    "    \"\"\"\n",
    "    Route Queries\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "    Returns:\n",
    "        state (dict): New key added to state that contains the route\n",
    "    \"\"\"\n",
    "    print(\"---ROUTING---\")\n",
    "    question = state[\"question\"]\n",
    "    chosen_route = ''\n",
    "\n",
    "    # Retrieval\n",
    "    if rl(question).name==None:\n",
    "        chosen_route =  \"web_search\"\n",
    "    else:\n",
    "        chosen_route = rl(question).name\n",
    "    return {'route': chosen_route}\n",
    "\n",
    "\n",
    "def retriever(state):\n",
    "    \"\"\"\n",
    "    Retrieving Docs\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "    Returns:\n",
    "        state (dict): New key added to state that contains the retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVING---\")\n",
    "    chosen_route = state['route']\n",
    "    question = state['question']\n",
    "    if chosen_route =='web_search' or chosen_route=='chitchat':\n",
    "        results = web_search_tool.invoke({\"query\": question})\n",
    "        result_content = [result['content'] for result in results]\n",
    "        docs = '/n'.join(result_content)\n",
    "    elif chosen_route=='ai':\n",
    "        docs = arxiv.run(question)\n",
    "    elif chosen_route=='recipes':\n",
    "        results = recipe_retriever.invoke(question)\n",
    "        result_content = [result.page_content for result in results]\n",
    "        docs = '/n'.join(result_content)\n",
    "    return {'documents': docs}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "    Returns:\n",
    "        state (dict): Adds a document relevance score to the state\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---GRADE DOCUMENT RELEVANCE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    score = retrieval_grader.invoke({\"question\": question, \"document\": documents})\n",
    "    if score.lower() ==\"yes\":\n",
    "        print(\"Documents are relevant\")\n",
    "    else:\n",
    "        print(\"Documents are irrelevant\")\n",
    "    return {'score': score.lower()}\n",
    "\n",
    "\n",
    "def generate_answer(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---GENERATE ANSWER---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    score = state['score']\n",
    "    \n",
    "    if score == 'no':\n",
    "        ## Run websearch \n",
    "        results = web_search_tool.invoke({\"query\": question})\n",
    "        result_content = [result['content'] for result in results]\n",
    "        documents = '/n'.join(result_content)\n",
    "\n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {'answer': generation, 'documents': documents}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Graph Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"query_router\", query_router) \n",
    "workflow.add_node(\"retrieve\", retriever) \n",
    "workflow.add_node(\"grade_documents\", grade_documents)\n",
    "workflow.add_node(\"generate\", generate_answer)\n",
    "\n",
    "\n",
    "## Define Flow\n",
    "workflow.set_entry_point(\"query_router\")\n",
    "workflow.add_edge(\"query_router\", \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_edge(\"grade_documents\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   +-----------+     \n",
      "   | __start__ |     \n",
      "   +-----------+     \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "  +--------------+   \n",
      "  | query_router |   \n",
      "  +--------------+   \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "    +----------+     \n",
      "    | retrieve |     \n",
      "    +----------+     \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "+-----------------+  \n",
      "| grade_documents |  \n",
      "+-----------------+  \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "    +----------+     \n",
      "    | generate |     \n",
      "    +----------+     \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "    +---------+      \n",
      "    | __end__ |      \n",
      "    +---------+      \n"
     ]
    }
   ],
   "source": [
    "graph.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTING---\n",
      "{'query_router': {'route': 'recipes'}}\n",
      "---RETRIEVING---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_chain_end callback: AttributeError(\"'NoneType' object has no attribute 'append'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieve': {'documents': 'decorate with radish.Nutritional value per serving: \\nâ€¢ Calories: 36kcalâ€¢ Fat: 2g â€¢ Saturated fat: 0g â€¢ Cholesterol: 0gâ€¢ Carbohydrates: 4g â€¢ Protein: 1gâ€¢ Sodium: 93mgâ€¢ Fiber: 1gCucumber and Radish Salad\\nPreferred for\\nRamadan/nkcal = kilo calories; g = grams; mg = milligrams\\nWafaa Helmi Ayesh, Director of Clinical Nutrition Department. Clinical Support Services Sector  - Dubai Health Authority - UAEReference\\nÂ© 2013 - LifeScan Middle East & Africa a division of Johnson & Johnson (Middle East) Inc - AW MEA 0313CG-MEANAR-ED1.Ingredients:\\n10 radishes \\n2 pieces seedless cucumber \\n1 fresh hot pepper cut into rings without seeds  \\n2 tablespoons chopped fresh basil\\nÂ½ teaspoon sugar\\n1/4 teaspoon salt \\n1 tablespoon olive oil \\n1 tablespoon vinegar\\nPreparation:\\n1. Take one piece of radish aside for decoration. \\n2. Then cut 5 radishes into slices, and cut the rest of the radishes into halves or four. \\n3. Cut the cucumber into strips.\\n4. Take a pot and mix the sliced radish, cucumber ribbons, chili, basil, sugar, and \\nsalt.  \\n5. Add olive oil and white vinegar and mix all lightly to blend with vegetable and/nkcal = kilo calories; g = grams; mg = milligrams\\nWafaa Helmi Ayesh, Director of Clinical Nutrition Department. Clinical Support Services Sector  - Dubai Health Authority - UAEReference\\nÂ© 2013 - LifeScan Middle East & Africa a division of Johnson & Johnson (Middle East) Inc - AW MEA 0313CG-MEANAR-ED1.\\nIngredients:\\n1 small cabbage (or Â½ large cabbage) \\n1 carrot \\nÂ½ cup labna1 tablespoon mayonnaise\\n2 tablespoons low-fat yoghurt\\nÂ½ tablespoon sugar \\nÂ½ teaspoon vinegar\\nPreparation:\\n1. Grate the carrots.\\n2. Mix the following ingredients: mayonnaise, labna, milk, sugar and vinegar.\\n3. Soak the carrot with the above sauce and cover it. Keep in refrigerator for 20 mins. \\n4. Chop or shred the cabbage. \\n5. Combine the cabbage, carrots and sauce serve cold.Cabbage Salad (Coleslaw) \\nThis dish is enough for 4 people and is prepared in a way to make it low in calories for those who \\nfollow a healthy diet or weight reducing diet./n5. Mix in a deep dish the yoghurt, curry, salt and pepper until mix become homogeneous. \\n6. Put the vegetables in a deep dish and add this sauce. \\n7. Put chopped almonds on top.Preferred for\\nRamadan'}}\n",
      "---GRADE DOCUMENT RELEVANCE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_chain_end callback: AttributeError(\"'NoneType' object has no attribute 'append'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents are relevant\n",
      "{'grade_documents': {'score': 'yes'}}\n",
      "---GENERATE ANSWER---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_chain_end callback: AttributeError(\"'NoneType' object has no attribute 'append'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generate': {'documents': 'decorate with radish.Nutritional value per serving: \\nâ€¢ Calories: 36kcalâ€¢ Fat: 2g â€¢ Saturated fat: 0g â€¢ Cholesterol: 0gâ€¢ Carbohydrates: 4g â€¢ Protein: 1gâ€¢ Sodium: 93mgâ€¢ Fiber: 1gCucumber and Radish Salad\\nPreferred for\\nRamadan/nkcal = kilo calories; g = grams; mg = milligrams\\nWafaa Helmi Ayesh, Director of Clinical Nutrition Department. Clinical Support Services Sector  - Dubai Health Authority - UAEReference\\nÂ© 2013 - LifeScan Middle East & Africa a division of Johnson & Johnson (Middle East) Inc - AW MEA 0313CG-MEANAR-ED1.Ingredients:\\n10 radishes \\n2 pieces seedless cucumber \\n1 fresh hot pepper cut into rings without seeds  \\n2 tablespoons chopped fresh basil\\nÂ½ teaspoon sugar\\n1/4 teaspoon salt \\n1 tablespoon olive oil \\n1 tablespoon vinegar\\nPreparation:\\n1. Take one piece of radish aside for decoration. \\n2. Then cut 5 radishes into slices, and cut the rest of the radishes into halves or four. \\n3. Cut the cucumber into strips.\\n4. Take a pot and mix the sliced radish, cucumber ribbons, chili, basil, sugar, and \\nsalt.  \\n5. Add olive oil and white vinegar and mix all lightly to blend with vegetable and/nkcal = kilo calories; g = grams; mg = milligrams\\nWafaa Helmi Ayesh, Director of Clinical Nutrition Department. Clinical Support Services Sector  - Dubai Health Authority - UAEReference\\nÂ© 2013 - LifeScan Middle East & Africa a division of Johnson & Johnson (Middle East) Inc - AW MEA 0313CG-MEANAR-ED1.\\nIngredients:\\n1 small cabbage (or Â½ large cabbage) \\n1 carrot \\nÂ½ cup labna1 tablespoon mayonnaise\\n2 tablespoons low-fat yoghurt\\nÂ½ tablespoon sugar \\nÂ½ teaspoon vinegar\\nPreparation:\\n1. Grate the carrots.\\n2. Mix the following ingredients: mayonnaise, labna, milk, sugar and vinegar.\\n3. Soak the carrot with the above sauce and cover it. Keep in refrigerator for 20 mins. \\n4. Chop or shred the cabbage. \\n5. Combine the cabbage, carrots and sauce serve cold.Cabbage Salad (Coleslaw) \\nThis dish is enough for 4 people and is prepared in a way to make it low in calories for those who \\nfollow a healthy diet or weight reducing diet./n5. Mix in a deep dish the yoghurt, curry, salt and pepper until mix become homogeneous. \\n6. Put the vegetables in a deep dish and add this sauce. \\n7. Put chopped almonds on top.Preferred for\\nRamadan', 'answer': 'Cucumber and Radish Salad Recipe:\\n\\nIngredients:\\n- 10 radishes\\n- 2 seedless cucumbers\\n- 1 fresh hot pepper (without seeds), cut into rings\\n- 2 tablespoons chopped fresh basil\\n- 1/2 teaspoon sugar\\n- 1/4 teaspoon salt\\n- 1 tablespoon olive oil\\n- 1 tablespoon vinegar\\n\\nPreparation:\\n1. Set aside one radish for decoration.\\n2. Slice 5 radishes and cut the rest into halves or quarters.\\n3. Cut the cucumbers into strips.\\n4. In a bowl, mix the sliced radishes, cucumber strips, hot pepper, basil, sugar, and salt.\\n5. Add olive oil and vinegar, then lightly mix to blend with the vegetables.\\n6. Decorate with the remaining radish.\\n\\nEnjoy your Cucumber and Radish Salad!'}}\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for s in graph.stream({\n",
    "    'question': \"Share the recipe for cucumber and radish salad\",\n",
    "}, thread):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cucumber and Radish Salad Recipe:\\n'\n",
      " '\\n'\n",
      " 'Ingredients:\\n'\n",
      " '- 10 radishes\\n'\n",
      " '- 2 seedless cucumbers\\n'\n",
      " '- 1 fresh hot pepper (without seeds), cut into rings\\n'\n",
      " '- 2 tablespoons chopped fresh basil\\n'\n",
      " '- 1/2 teaspoon sugar\\n'\n",
      " '- 1/4 teaspoon salt\\n'\n",
      " '- 1 tablespoon olive oil\\n'\n",
      " '- 1 tablespoon vinegar\\n'\n",
      " '\\n'\n",
      " 'Preparation:\\n'\n",
      " '1. Set aside one radish for decoration.\\n'\n",
      " '2. Slice 5 radishes and cut the rest into halves or quarters.\\n'\n",
      " '3. Cut the cucumbers into strips.\\n'\n",
      " '4. In a bowl, mix the sliced radishes, cucumber strips, hot pepper, basil, '\n",
      " 'sugar, and salt.\\n'\n",
      " '5. Add olive oil and vinegar, then lightly mix to blend with the '\n",
      " 'vegetables.\\n'\n",
      " '6. Decorate with the remaining radish.\\n'\n",
      " '\\n'\n",
      " 'Enjoy your Cucumber and Radish Salad!')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(s['generate']['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTING---\n",
      "{'query_router': {'route': 'ai'}}\n",
      "---RETRIEVING---\n",
      "{'retrieve': {'documents': 'Published: 2024-05-09\\nTitle: Hypothesis Testing Prompting Improves Deductive Reasoning in Large Language Models\\nAuthors: Yitian Li, Jidong Tian, Hao He, Yaohui Jin\\nSummary: Combining different forms of prompts with pre-trained large language models\\nhas yielded remarkable results on reasoning tasks (e.g. Chain-of-Thought\\nprompting). However, along with testing on more complex reasoning, these\\nmethods also expose problems such as invalid reasoning and fictional reasoning\\npaths. In this paper, we develop \\\\textit{Hypothesis Testing Prompting}, which\\nadds conclusion assumptions, backward reasoning, and fact verification during\\nintermediate reasoning steps. \\\\textit{Hypothesis Testing prompting} involves\\nmultiple assumptions and reverses validation of conclusions leading to its\\nunique correct answer. Experiments on two challenging deductive reasoning\\ndatasets ProofWriter and RuleTaker show that hypothesis testing prompting not\\nonly significantly improves the effect, but also generates a more reasonable\\nand standardized reasoning process.\\n\\nPublished: 2023-10-09\\nTitle: Guiding Large Language Models via Directional Stimulus Prompting\\nAuthors: Zekun Li, Baolin Peng, Pengcheng He, Michel Galley, Jianfeng Gao, Xifeng Yan\\nSummary: We introduce Directional Stimulus Prompting, a novel framework for guiding\\nblack-box large language models (LLMs) toward specific desired outputs. Instead\\nof directly adjusting LLMs, our method employs a small tunable policy model\\n(e.g., T5) to generate an auxiliary directional stimulus prompt for each input\\ninstance. These directional stimulus prompts act as nuanced, instance-specific\\nhints and clues to guide LLMs in generating desired outcomes, such as including\\nspecific keywords in the generated summary. Our approach sidesteps the\\nchallenges of direct LLM tuning by optimizing the policy model to explore\\ndirectional stimulus prompts that align LLMs with desired behaviors. The policy\\nmodel can be optimized through 1) supervised fine-tuning using labeled data and\\n2) reinforcement learning from offline or online rewards based on the LLM\\'s\\noutput. We assess our method across summarization, dialogue response\\ngeneration, and chain-of-thought reasoning tasks. Our experiments demonstrate\\nthat the framework consistently improves LLMs\\' (e.g., ChatGPT, Codex,\\nInstructGPT) performance on these supervised tasks using minimal labeled data.\\nNotably, using just 80 dialogues on the MultiWOZ dataset, our approach enhances\\nChatGPT\\'s performance by an impressive 41.4%, matching or surpassing some fully\\nsupervised start-of-the-art models. Additionally, the instance-specific\\nchain-of-thought prompt generated by our approach improves InstructGPT\\'s\\nreasoning accuracy compared to human-crafted or automatically generated\\nprompts. The code and data are publicly available at\\n\\\\url{https://github.com/Leezekun/Directional-Stimulus-Prompting}.\\n\\nPublished: 2024-04-15\\nTitle: Symbolic Chain-of-Thought Distillation: Small Models Can Also \"Think\" Step-by-Step\\nAuthors: Liunian Harold Li, Jack Hessel, Youngjae Yu, Xiang Ren, Kai-Wei Chang, Yejin Choi\\nSummary: Chain-of-thought prompting (e.g., \"Let\\'s think step-by-step\") primes large\\nlanguage models to verbalize rationalization for their predictions. While\\nchain-of-thought can lead to dramatic performance gains, benefits appear to\\nemerge only for sufficiently large models (beyond 50B parameters). We show that\\norders-of-magnitude smaller models (125M -- 1.3B parameters) can still benefit\\nfrom chain-of-thought prompting. To achieve this, we introduce Symbolic\\nChain-of-Thought Distillation (SCoTD), a method to train a smaller student\\nmodel on rationalizations sampled from a significantly larger teacher model.\\nExperiments across several commonsense benchmarks show that: 1) SCoTD enhances\\nthe performance of the student model in both supervised and few-shot settings,\\nand especially for challenge sets; 2) sampling many reasoning chains per\\ninstance from the teacher is paramount; and 3) after distillation, student\\nchain-of-thoughts are judged by humans as comparable to the teacher, despite\\norders of magnitude fewer parameters. We test several hypotheses regarding what\\nproperties of chain-of-thought samples are important, e.g., diversity vs.\\nteacher likelihood vs. open-endedness. We release our corpus of\\nchain-of-thought samples and code.'}}\n",
      "---GRADE DOCUMENT RELEVANCE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_chain_end callback: AttributeError(\"'NoneType' object has no attribute 'append'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents are relevant\n",
      "{'grade_documents': {'score': 'yes'}}\n",
      "---GENERATE ANSWER---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_chain_end callback: AttributeError(\"'NoneType' object has no attribute 'append'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generate': {'documents': 'Published: 2024-05-09\\nTitle: Hypothesis Testing Prompting Improves Deductive Reasoning in Large Language Models\\nAuthors: Yitian Li, Jidong Tian, Hao He, Yaohui Jin\\nSummary: Combining different forms of prompts with pre-trained large language models\\nhas yielded remarkable results on reasoning tasks (e.g. Chain-of-Thought\\nprompting). However, along with testing on more complex reasoning, these\\nmethods also expose problems such as invalid reasoning and fictional reasoning\\npaths. In this paper, we develop \\\\textit{Hypothesis Testing Prompting}, which\\nadds conclusion assumptions, backward reasoning, and fact verification during\\nintermediate reasoning steps. \\\\textit{Hypothesis Testing prompting} involves\\nmultiple assumptions and reverses validation of conclusions leading to its\\nunique correct answer. Experiments on two challenging deductive reasoning\\ndatasets ProofWriter and RuleTaker show that hypothesis testing prompting not\\nonly significantly improves the effect, but also generates a more reasonable\\nand standardized reasoning process.\\n\\nPublished: 2023-10-09\\nTitle: Guiding Large Language Models via Directional Stimulus Prompting\\nAuthors: Zekun Li, Baolin Peng, Pengcheng He, Michel Galley, Jianfeng Gao, Xifeng Yan\\nSummary: We introduce Directional Stimulus Prompting, a novel framework for guiding\\nblack-box large language models (LLMs) toward specific desired outputs. Instead\\nof directly adjusting LLMs, our method employs a small tunable policy model\\n(e.g., T5) to generate an auxiliary directional stimulus prompt for each input\\ninstance. These directional stimulus prompts act as nuanced, instance-specific\\nhints and clues to guide LLMs in generating desired outcomes, such as including\\nspecific keywords in the generated summary. Our approach sidesteps the\\nchallenges of direct LLM tuning by optimizing the policy model to explore\\ndirectional stimulus prompts that align LLMs with desired behaviors. The policy\\nmodel can be optimized through 1) supervised fine-tuning using labeled data and\\n2) reinforcement learning from offline or online rewards based on the LLM\\'s\\noutput. We assess our method across summarization, dialogue response\\ngeneration, and chain-of-thought reasoning tasks. Our experiments demonstrate\\nthat the framework consistently improves LLMs\\' (e.g., ChatGPT, Codex,\\nInstructGPT) performance on these supervised tasks using minimal labeled data.\\nNotably, using just 80 dialogues on the MultiWOZ dataset, our approach enhances\\nChatGPT\\'s performance by an impressive 41.4%, matching or surpassing some fully\\nsupervised start-of-the-art models. Additionally, the instance-specific\\nchain-of-thought prompt generated by our approach improves InstructGPT\\'s\\nreasoning accuracy compared to human-crafted or automatically generated\\nprompts. The code and data are publicly available at\\n\\\\url{https://github.com/Leezekun/Directional-Stimulus-Prompting}.\\n\\nPublished: 2024-04-15\\nTitle: Symbolic Chain-of-Thought Distillation: Small Models Can Also \"Think\" Step-by-Step\\nAuthors: Liunian Harold Li, Jack Hessel, Youngjae Yu, Xiang Ren, Kai-Wei Chang, Yejin Choi\\nSummary: Chain-of-thought prompting (e.g., \"Let\\'s think step-by-step\") primes large\\nlanguage models to verbalize rationalization for their predictions. While\\nchain-of-thought can lead to dramatic performance gains, benefits appear to\\nemerge only for sufficiently large models (beyond 50B parameters). We show that\\norders-of-magnitude smaller models (125M -- 1.3B parameters) can still benefit\\nfrom chain-of-thought prompting. To achieve this, we introduce Symbolic\\nChain-of-Thought Distillation (SCoTD), a method to train a smaller student\\nmodel on rationalizations sampled from a significantly larger teacher model.\\nExperiments across several commonsense benchmarks show that: 1) SCoTD enhances\\nthe performance of the student model in both supervised and few-shot settings,\\nand especially for challenge sets; 2) sampling many reasoning chains per\\ninstance from the teacher is paramount; and 3) after distillation, student\\nchain-of-thoughts are judged by humans as comparable to the teacher, despite\\norders of magnitude fewer parameters. We test several hypotheses regarding what\\nproperties of chain-of-thought samples are important, e.g., diversity vs.\\nteacher likelihood vs. open-endedness. We release our corpus of\\nchain-of-thought samples and code.', 'answer': 'Chain of Thought prompting is a method that primes large language models to verbalize rationalization for their predictions. It involves guiding the model through a series of reasoning steps to improve reasoning accuracy and generate a more reasonable and standardized reasoning process.'}}\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for s in graph.stream({\n",
    "    'question': \"What is Chain of Thought prompting?\",\n",
    "}, thread):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Chain of Thought prompting is a method that primes large language models to '\n",
      " 'verbalize rationalization for their predictions. It involves guiding the '\n",
      " 'model through a series of reasoning steps to improve reasoning accuracy and '\n",
      " 'generate a more reasonable and standardized reasoning process.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(s['generate']['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---ROUTING---\n",
      "{'query_router': {'route': 'web_search'}}\n",
      "---RETRIEVING---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_chain_end callback: AttributeError(\"'NoneType' object has no attribute 'append'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieve': {'documents': 'Change currency. Feedback. Help. Flights from New York to Los Angeles. Use Google Flights to plan your next trip and find cheap one way or round trip flights from New York to Los Angeles./nNonstop departures\\nMonday\\nAeromexico, Air China, Air Europa, +27 more\\nAeromexico, Air China, +28 more\\n26\\n27\\nTuesday\\nAeromexico, Air Europa, Air France, +28 more\\nAeromexico, Air Europa, +29 more\\n27\\n28\\nWednesday\\nAeromexico, Air China, Air Europa, +27 more\\nAeromexico, Air China, +28 more\\n26\\n27\\nThursday\\nAeromexico, Air Europa, Air France, +26 more\\nAeromexico, Air Europa, +27 more\\n25\\n26\\nFriday\\nAeromexico, Air Europa, Air France, +27 more\\nAeromexico, Air Europa, +28 more\\n26\\n27\\nSaturday\\nAeromexico, Air China, Air Europa, +27 more\\nAeromexico, Air China, +28 more\\n26\\n27\\nSunday\\nAeromexico, Air Europa, Air France, +26 more\\nAeromexico, Air Europa, +27 more\\n25\\n26\\nNonstop returns\\nMonday\\nAeromexico, Air Europa, Air France, +26 more\\nAeromexico, Air Europa, +27 more\\n25\\n26\\nTuesday\\nAeromexico, Air Europa, Air France, +27 more\\nAeromexico, Air Europa, +28 more\\n26\\n27\\nWednesday\\nAeromexico, Air Europa, Air France, +26 more\\nAeromexico, Air Europa, +27 more\\n25\\n26\\nThursday\\nAeromexico, Air Europa, Air France, +26 more\\nAeromexico, Air Europa, +27 more\\n25\\n26\\nFriday\\nAeromexico, Air Europa, Air France, +25 more\\nAeromexico, Air Europa, +26 more\\n24\\n25\\nSaturday\\nAeromexico, Air Europa, Air France, +26 more\\nAeromexico, Air Europa, +27 more\\n25\\n26\\nSunday\\nAeromexico, Air Europa, Air France, +27 more\\nAeromexico, Air Europa, +28 more\\n26\\n27\\nTop 5 airlines serving from New York to Los Angeles\\nItÃ¢â‚¬â„¢s ridiculous to not have TV screens for a flight that is 5hours long!!!! Book cheap flights from New York to Los Angeles\\nRecent one-way flight deals\\nSearch by stops\\nSearch by airline\\nSearch by price\\nLast minute flights from New York to Los Angeles\\nLast minute flight, train and bus deals\\nSearch by stops\\nSearch by airline\\nSearch by price\\nFlights to Los Angeles\\nDestination:\\nLos Angeles (LAX)United States\\nReturn flight deals:\\nLos Angeles - New York\\nCabin classes:\\n Flights from New York to Los Angeles - Travel Insights & Trends\\nGood to know\\nWhen to book flights from New York to Los Angeles\\nFAQs for booking flights from New York to Los Angeles\\nLAX is devoted to meeting the needs of all its customers and has numerous accessible facilities. Top tips for finding a cheap flight from New York to Los Angeles\\nPrefer to fly non-stop from New York to Los Angeles?\\nFind which airlines fly direct from New York to Los Angeles, which days they fly and book direct flights.\\n Search hundreds of travel sites at once for deals on flights to Los Angeles\\nHow much is the cheapest flight from New York to Los Angeles?\\n/nThe most efficient way to travel from New York to Los Angeles is by flying, which takes around 8 hours and 40 minutes with prices ranging from $100 to $430. Alternatively, you can opt for a bus journey, which takes approximately 2 days and 14 hours, with costs ranging from $310 to $650. Another option is to take a train route via New Orleans ...'}}\n",
      "---GRADE DOCUMENT RELEVANCE---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_chain_end callback: AttributeError(\"'NoneType' object has no attribute 'append'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents are relevant\n",
      "{'grade_documents': {'score': 'yes'}}\n",
      "---GENERATE ANSWER---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_chain_end callback: AttributeError(\"'NoneType' object has no attribute 'append'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generate': {'documents': 'Change currency. Feedback. Help. Flights from New York to Los Angeles. Use Google Flights to plan your next trip and find cheap one way or round trip flights from New York to Los Angeles./nNonstop departures\\nMonday\\nAeromexico, Air China, Air Europa, +27 more\\nAeromexico, Air China, +28 more\\n26\\n27\\nTuesday\\nAeromexico, Air Europa, Air France, +28 more\\nAeromexico, Air Europa, +29 more\\n27\\n28\\nWednesday\\nAeromexico, Air China, Air Europa, +27 more\\nAeromexico, Air China, +28 more\\n26\\n27\\nThursday\\nAeromexico, Air Europa, Air France, +26 more\\nAeromexico, Air Europa, +27 more\\n25\\n26\\nFriday\\nAeromexico, Air Europa, Air France, +27 more\\nAeromexico, Air Europa, +28 more\\n26\\n27\\nSaturday\\nAeromexico, Air China, Air Europa, +27 more\\nAeromexico, Air China, +28 more\\n26\\n27\\nSunday\\nAeromexico, Air Europa, Air France, +26 more\\nAeromexico, Air Europa, +27 more\\n25\\n26\\nNonstop returns\\nMonday\\nAeromexico, Air Europa, Air France, +26 more\\nAeromexico, Air Europa, +27 more\\n25\\n26\\nTuesday\\nAeromexico, Air Europa, Air France, +27 more\\nAeromexico, Air Europa, +28 more\\n26\\n27\\nWednesday\\nAeromexico, Air Europa, Air France, +26 more\\nAeromexico, Air Europa, +27 more\\n25\\n26\\nThursday\\nAeromexico, Air Europa, Air France, +26 more\\nAeromexico, Air Europa, +27 more\\n25\\n26\\nFriday\\nAeromexico, Air Europa, Air France, +25 more\\nAeromexico, Air Europa, +26 more\\n24\\n25\\nSaturday\\nAeromexico, Air Europa, Air France, +26 more\\nAeromexico, Air Europa, +27 more\\n25\\n26\\nSunday\\nAeromexico, Air Europa, Air France, +27 more\\nAeromexico, Air Europa, +28 more\\n26\\n27\\nTop 5 airlines serving from New York to Los Angeles\\nItÃ¢â‚¬â„¢s ridiculous to not have TV screens for a flight that is 5hours long!!!! Book cheap flights from New York to Los Angeles\\nRecent one-way flight deals\\nSearch by stops\\nSearch by airline\\nSearch by price\\nLast minute flights from New York to Los Angeles\\nLast minute flight, train and bus deals\\nSearch by stops\\nSearch by airline\\nSearch by price\\nFlights to Los Angeles\\nDestination:\\nLos Angeles (LAX)United States\\nReturn flight deals:\\nLos Angeles - New York\\nCabin classes:\\n Flights from New York to Los Angeles - Travel Insights & Trends\\nGood to know\\nWhen to book flights from New York to Los Angeles\\nFAQs for booking flights from New York to Los Angeles\\nLAX is devoted to meeting the needs of all its customers and has numerous accessible facilities. Top tips for finding a cheap flight from New York to Los Angeles\\nPrefer to fly non-stop from New York to Los Angeles?\\nFind which airlines fly direct from New York to Los Angeles, which days they fly and book direct flights.\\n Search hundreds of travel sites at once for deals on flights to Los Angeles\\nHow much is the cheapest flight from New York to Los Angeles?\\n/nThe most efficient way to travel from New York to Los Angeles is by flying, which takes around 8 hours and 40 minutes with prices ranging from $100 to $430. Alternatively, you can opt for a bus journey, which takes approximately 2 days and 14 hours, with costs ranging from $310 to $650. Another option is to take a train route via New Orleans ...', 'answer': 'The most efficient and cheapest way to travel from New York to Los Angeles is by flying, with prices ranging from $100 to $430.'}}\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for s in graph.stream({\n",
    "    'question': \"What are the different ways to go from NY to LA and which is the cheapest?\",\n",
    "}, thread):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The most efficient and cheapest way to travel from New York to Los Angeles '\n",
      " 'is by flying, with prices ranging from $100 to $430.')\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(s['generate']['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
