{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Assistant with Code Checks\n",
    "\n",
    "Idea borrowed from Langchain: https://www.youtube.com/watch?v=MvNdgmM7uyc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![coding_assistant](images/code-assistant.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import pprint\n",
    "import subprocess\n",
    "##to load credentials\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") ## Put your OpenAI API key here\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\") ## Put your Langsmith API key here\n",
    "os.environ[\"LANGCHAIN_HUB_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\") ## Put your Langsmith API key here\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = 'true' ## Set this as True\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = 'https://api.smith.langchain.com/' ## Set this as: https://api.smith.langchain.com/\n",
    "os.environ[\"LANGCHAIN_HUB_API_URL\"] = 'https://api.hub.langchain.com' ## Set this as : https://api.hub.langchain.com\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = 'llm-agents'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Code Generation node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Prompt\n",
    "system_prompt = '''You are an expert coding assistant. You help answer the coding request from the user.\n",
    "You should focus on generating concise and accurate code\n",
    "I need you to answer in JSON format with the following 4 outputs:\n",
    "1. Code description - under key description\n",
    "2. Code Imports - under key imports\n",
    "3. Main body of the code - under key code\n",
    "4. One test case of the code with the expected output - under a dictionary test with input key and output key. Input should include the name of the function along with sample inputs\n",
    "\n",
    "Don't include \\n in your JSON output except in the code key as needed\n",
    "Example of this is:\n",
    "User Request: I need the code to generate fibonacci numbers\n",
    "Answer: \n",
    "{{\n",
    "  \"description\": \"This function generates Fibonacci numbers up to a specified limit.\",\n",
    "  \"imports\": \"None\",\n",
    "  \"code\": \"def fibonacci(limit):\\n    sequence = [0, 1]\\n    for i in range(2, limit):\\n        sequence.append(sequence[i - 1] + sequence[i - 2])\\n    return sequence\",\n",
    "  \"test\": {{\n",
    "    \"input\": \" result = fibonacci(10) \\n print(result)\",\n",
    "    \"output\": \"[0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\"\n",
    "  }}\n",
    "}}\n",
    "\n",
    "Look at the chain of messages below that include the user request. If your previous code had an error, you can use that to revise your code\n",
    "Message History: {messages}\n",
    "'''\n",
    "\n",
    "generate_answer_prompt = PromptTemplate(\n",
    "        input_variables=[\"messages\"], template=system_prompt)\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0.1, model_kwargs={\"response_format\": {\"type\": \"json_object\"}},)\n",
    "\n",
    "# LLM Chain\n",
    "code_generation = generate_answer_prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 'def find_largest_index(numbers):\\n'\n",
      "         '    if not numbers:\\n'\n",
      "         '        return None\\n'\n",
      "         '    largest_index = 0\\n'\n",
      "         '    for i in range(1, len(numbers)):\\n'\n",
      "         '        if numbers[i] > numbers[largest_index]:\\n'\n",
      "         '            largest_index = i\\n'\n",
      "         '    return largest_index',\n",
      " 'description': 'This function finds the index of the largest number in a '\n",
      "                'list.',\n",
      " 'imports': 'None',\n",
      " 'test': {'input': 'result = find_largest_index([3, 1, 4, 1, 5, 9, 2, 6, 5, 3, '\n",
      "                   '5])\\n'\n",
      "                   'print(result)',\n",
      "          'output': '5'}}\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "messages = list(\"How do I find the location of the largest number in a list in python?\")\n",
    "generation = code_generation.invoke({\"messages\": messages}).content\n",
    "generation = json.loads(generation)\n",
    "pprint.pprint(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the generated code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def find_largest_index(numbers):\n",
      "    if not numbers:\n",
      "        return None\n",
      "    largest_index = 0\n",
      "    for i in range(1, len(numbers)):\n",
      "        if numbers[i] > numbers[largest_index]:\n",
      "            largest_index = i\n",
      "    return largest_index\n",
      "result = find_largest_index([3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5])\n",
      "print(result)\n",
      "5\n",
      "Code executed successfully\n"
     ]
    }
   ],
   "source": [
    "code_block = generation['code'] + '\\n' + generation['test']['input']\n",
    "print(code_block)\n",
    "try:\n",
    "    exec(code_block)\n",
    "    print(\"Code executed successfully\")  # Only reached if no exceptions\n",
    "except Exception as e:  # Catch any type of exception\n",
    "    print(f\"Error executing code: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Evaluate the input string to get the function call and arguments\n",
    "    test_case = code_block\n",
    "    with open(\"temp_test.py\", \"w\") as f:\n",
    "        f.write(test_case)\n",
    "\n",
    "    # Build the command to execute the temporary file\n",
    "    command = [\"python\", \"temp_test.py\"]  # Replace with your python execution path if needed\n",
    "\n",
    "    # Run the command and capture the output\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "    # Convert the expected output to the correct data type (integer in this case)\n",
    "    expected_output = int(generation['test']['output']) \n",
    "\n",
    "    # Check if the process ran successfully\n",
    "    if result.returncode == 0:\n",
    "        output = int(result.stdout.strip())  # Get the output and convert to int\n",
    "        if output == expected_output:\n",
    "            print(\"Test passed!\")\n",
    "        else:\n",
    "            print(f\"Test failed. Expected: {expected_output}, Got: {output}\")\n",
    "    else:\n",
    "        print(\"Error executing code:\", result.stderr)\n",
    "except Exception as e:  # Catch any type of exception\n",
    "    print(f\"Error executing code: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Langgraph graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        code_generation: Code generated by the code generator\n",
    "        error: tracks whether code executed without error\n",
    "        messages : With user question, error messages, reasoning\n",
    "        iterations: Total number of iterations\n",
    "    \"\"\"\n",
    "\n",
    "    code_generation: dict\n",
    "    error: bool\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    iterations: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameters\n",
    "max_iterations = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Graph Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_generation_node(state: GraphState):\n",
    "    \"\"\"\n",
    "    Code Generation and re-generation for an error\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state - code solution\n",
    "    \"\"\"\n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "    error = state[\"error\"]\n",
    "\n",
    "    ## Generate code for the first time\n",
    "    if error == \"no\":\n",
    "        code_solution = code_generation.invoke(messages).content\n",
    "        code_solution = json.loads(code_solution)\n",
    "        \n",
    "        messages += [\n",
    "            (\n",
    "                \"assistant\",\n",
    "                f\"Here is my attempt to solve the problem: {code_solution['description']} \\n Imports: {code_solution['imports']} \\n Code: {code_solution['code']}. The test case I shared are \\n Test Case: {code_solution['test']}\",\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Increment\n",
    "        iterations = iterations + 1\n",
    "        return {\"code_generation\": code_generation, \"messages\": messages, \"iterations\": iterations}\n",
    "    \n",
    "    elif error == \"yes\":\n",
    "        ## Regenerate to fix error\n",
    "        messages += [\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Your code did not run successfully. Look at the message history to check errors. Regenerate a new code following the JSON output format I want \",\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Solution\n",
    "        code_solution = code_generation.invoke(messages).content\n",
    "        code_solution = json.loads(code_solution)\n",
    "\n",
    "        messages += [\n",
    "            (\n",
    "                \"assistant\",\n",
    "                f\"Here is my new solution: {code_solution['description']} \\n Imports: {code_solution['imports']} \\n Code: {code_solution['code']}. The test case I shared are \\n Test Case: {code_solution['test']}\",\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Increment\n",
    "        iterations = iterations + 1\n",
    "        return {\"code_generation\": code_solution, \"messages\": messages, \"iterations\": iterations}\n",
    "\n",
    "\n",
    "def code_execution_check(state: GraphState):\n",
    "    \"\"\"\n",
    "    Check code\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, error. Messages updated with error\n",
    "    \"\"\"\n",
    "    print(\"----CHECKING CODE EXECUTION---------\")\n",
    "    # State\n",
    "    code_solution = state[\"code_generation\"].content\n",
    "    code_solution = json.loads(code_solution)\n",
    "    print(\"Code Solution: \", code_solution)\n",
    "    imports = code_solution['imports']\n",
    "    code = code_solution['code']\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # Check imports\n",
    "    try:\n",
    "        exec(imports)\n",
    "    except Exception as e:\n",
    "        print(\"---CODE IMPORT CHECK: FAILED---\")\n",
    "        error_message = [(\"user\", f\"Your solution failed the import test: {e}\")]\n",
    "        messages += error_message\n",
    "        return {\n",
    "            \"messages\": messages,\n",
    "            \"error\": \"yes\",\n",
    "        }\n",
    "\n",
    "    # Check execution\n",
    "    try:\n",
    "        exec(imports + \"\\n\" + code)\n",
    "    except Exception as e:\n",
    "        print(\"---CODE BLOCK CHECK: FAILED---\")\n",
    "        error_message = [(\"user\", f\"Your solution failed the code execution test: {e}\")]\n",
    "        messages += error_message\n",
    "        return {\n",
    "            \"messages\": messages,\n",
    "            \"error\": \"yes\",\n",
    "        }\n",
    "\n",
    "    # No errors\n",
    "    print(\"---NO CODE EXECUTION FAILURES---\")\n",
    "    return {\n",
    "        \"messages\": messages,\n",
    "        \"error\": \"no\",\n",
    "    }\n",
    "\n",
    "\n",
    "def code_test_cases_check(state: GraphState):\n",
    "    \"\"\"\n",
    "    Check test case from the LLM\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, error. Messages updated with error\n",
    "    \"\"\"\n",
    "    print(\"----CHECKING TEST CASES---------\")\n",
    "\n",
    "    # State\n",
    "    code_solution = state[\"code_generation\"].content\n",
    "    code_solution = json.loads(code_solution)\n",
    "\n",
    "    imports = code_solution['imports']\n",
    "    code = code_solution['code']\n",
    "    test_input = code_solution['test']['input']\n",
    "    test_output = code_solution['test']['output']\n",
    "    messages = state['messages']\n",
    "\n",
    "    if imports != \"None\":\n",
    "        full_code = imports + \"\\n\" + code + \"\\n\" + test_input\n",
    "    else:\n",
    "        full_code = code + \"\\n\" + test_input\n",
    "\n",
    "    ## Check test input\n",
    "    try:\n",
    "        # Evaluate the input string to get the function call and arguments\n",
    "        with open(\"temp_test.py\", \"w\") as f:\n",
    "            f.write(full_code)\n",
    "\n",
    "        # Build the command to execute the temporary file\n",
    "        command = [\"python\", \"temp_test.py\"]  # Replace with your python execution path if needed\n",
    "\n",
    "        # Run the command and capture the output\n",
    "        result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "        # Check if the process ran successfully\n",
    "        if result.returncode == 0:\n",
    "            output = result.stdout.strip()  # Get the output and convert to int\n",
    "            if str(output) == str(test_output):\n",
    "                print(\"TEST CASE CHECK - PASSED!\")\n",
    "                return {\n",
    "                \"messages\": messages,\n",
    "                \"error\": \"no\",\n",
    "                }\n",
    "            else:\n",
    "                print(\"---TEST CASE CHECK: FAILED---\")\n",
    "                error_message = [(\"user\", f\"Your test case run failed. Expected: {expected_output}, Got: {output}\")]\n",
    "                messages += error_message\n",
    "                return {\n",
    "                    \"messages\": messages,\n",
    "                    \"error\": \"yes\",\n",
    "                }\n",
    "        else:\n",
    "            print(\"---TEST CASE CHECK: FAILED---\")\n",
    "            error_message = [(\"user\", f\"Your test case run failed: { result.stderr}\")]\n",
    "            messages += error_message\n",
    "            return {\n",
    "                \"messages\": messages,\n",
    "                \"error\": \"yes\",\n",
    "            }\n",
    "    except Exception as e:  # Catch any type of exception\n",
    "        print(\"---TEST CASE CHECK: FAILED---\")\n",
    "        error_message = [(\"user\", f\"Your test case run failed with exception: {e}\")]\n",
    "        messages += error_message\n",
    "        return {\n",
    "            \"messages\": messages,\n",
    "            \"error\": \"yes\",\n",
    "        }\n",
    "\n",
    "## Add conditional edges\n",
    "\n",
    "def run_test_cases(state: GraphState):\n",
    "    \"\"\"\n",
    "    Determines whether to run test cases.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "    error = state[\"error\"]\n",
    "\n",
    "    if error == \"no\":\n",
    "        print(\"---DECISION: Code Worked. Run Test cases---\")\n",
    "        return \"test_cases\"\n",
    "    else:\n",
    "        print(\"---DECISION: RE-TRY CODE GENERATION---\")\n",
    "        return \"generate\"\n",
    "\n",
    "def end_flow_decision(state: GraphState):\n",
    "    \"\"\"\n",
    "    Determines whether to finish.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "    error = state[\"error\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "\n",
    "    if error == \"no\" or iterations == max_iterations:\n",
    "        print(\"---DECISION: FINISH---\")\n",
    "        return \"end\"\n",
    "    else:\n",
    "        print(\"---DECISION: RE-TRY SOLUTION---\")\n",
    "        return \"generate\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Graph Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"generate\", code_generation_node) \n",
    "workflow.add_node(\"check_code\", code_execution_check) \n",
    "workflow.add_node(\"test_cases\", code_test_cases_check) \n",
    "\n",
    "# Build graph\n",
    "workflow.set_entry_point(\"generate\")\n",
    "workflow.add_edge(\"generate\", \"check_code\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_code\",\n",
    "    run_test_cases,\n",
    "    {\n",
    "        \"test_cases\": \"test_cases\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"test_cases\",\n",
    "    end_flow_decision,\n",
    "    {\n",
    "        \"end\": END,\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          +-----------+                    \n",
      "                          | __start__ |                    \n",
      "                          +-----------+                    \n",
      "                                 *                         \n",
      "                                 *                         \n",
      "                                 *                         \n",
      "                           +----------+                    \n",
      "                           | generate |*                   \n",
      "                       ****+----------+ ****               \n",
      "                  *****          *          ****           \n",
      "              ****              *               ****       \n",
      "           ***                  *                   ****   \n",
      "+------------+                  *                       ***\n",
      "| check_code |               ***                          *\n",
      "+------------+              *                             *\n",
      "            ***          ***                              *\n",
      "               *        *                                 *\n",
      "                **    **                                  *\n",
      "          +----------------+                              *\n",
      "          | run_test_cases |                              *\n",
      "          +----------------+                              *\n",
      "                    *                                     *\n",
      "                    *                                     *\n",
      "                    *                                     *\n",
      "            +------------+                              ***\n",
      "            | test_cases |                          ****   \n",
      "            +------------+                      ****       \n",
      "                          **                ****           \n",
      "                            **          ****               \n",
      "                              **     ***                   \n",
      "                      +-------------------+                \n",
      "                      | end_flow_decision |                \n",
      "                      +-------------------+                \n",
      "                                 *                         \n",
      "                                 *                         \n",
      "                                 *                         \n",
      "                            +---------+                    \n",
      "                            | __end__ |                    \n",
      "                            +---------+                    \n"
     ]
    }
   ],
   "source": [
    "graph.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'no', 'messages': [HumanMessage(content='Write a Python program that finds the index of the maximum value in a list.', id='f5b4b05d-decd-43dd-b723-4dcc973f6abb')], 'iterations': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_chain_end callback: AttributeError(\"'NoneType' object has no attribute 'append'\")\n",
      "Error in LangChainTracer.on_chain_end callback: AttributeError(\"'NoneType' object has no attribute 'append'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code_generation': AIMessage(content='{\\n  \"description\": \"This function finds the index of the maximum value in a list.\",\\n  \"imports\": \"None\",\\n  \"code\": \"def find_max_index(lst):\\\\n    if not lst:\\\\n        return -1\\\\n    max_index = 0\\\\n    for i in range(1, len(lst)):\\\\n        if lst[i] > lst[max_index]:\\\\n            max_index = i\\\\n    return max_index\",\\n  \"test\": {\\n    \"input\": \"result = find_max_index([1, 3, 7, 2, 5])\\\\nprint(result)\",\\n    \"output\": \"2\"\\n  }\\n}', response_metadata={'token_usage': {'completion_tokens': 138, 'prompt_tokens': 502, 'total_tokens': 640}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_f4e629d0a5', 'finish_reason': 'stop', 'logprobs': None}, id='run-30d560cf-7652-4dbd-85e5-1a025b53e335-0'), 'error': 'no', 'messages': [HumanMessage(content='Write a Python program that finds the index of the maximum value in a list.', id='f5b4b05d-decd-43dd-b723-4dcc973f6abb'), AIMessage(content=\"Here is my attempt to solve the problem: This function finds the index of the maximum value in a list. \\n Imports: None \\n Code: def find_max_index(lst):\\n    if not lst:\\n        return -1\\n    max_index = 0\\n    for i in range(1, len(lst)):\\n        if lst[i] > lst[max_index]:\\n            max_index = i\\n    return max_index. The test case I shared are \\n Test Case: {'input': 'result = find_max_index([1, 3, 7, 2, 5])\\\\nprint(result)', 'output': '2'}\", id='68f9518b-e95d-42ec-9c81-a81921166d3c'), AIMessage(content=\"Here is my attempt to solve the problem: This function finds the index of the maximum value in a list. \\n Imports: None \\n Code: def find_max_index(lst):\\n    if not lst:\\n        return -1\\n    max_index = 0\\n    for i in range(1, len(lst)):\\n        if lst[i] > lst[max_index]:\\n            max_index = i\\n    return max_index. The test case I shared are \\n Test Case: {'input': 'result = find_max_index([1, 3, 7, 2, 5])\\\\nprint(result)', 'output': '2'}\", id='00707d2c-83d0-4635-bb1f-06368e1f8c05')], 'iterations': 1}\n",
      "----CHECKING CODE EXECUTION---------\n",
      "Code Solution:  {'description': 'This function finds the index of the maximum value in a list.', 'imports': 'None', 'code': 'def find_max_index(lst):\\n    if not lst:\\n        return -1\\n    max_index = 0\\n    for i in range(1, len(lst)):\\n        if lst[i] > lst[max_index]:\\n            max_index = i\\n    return max_index', 'test': {'input': 'result = find_max_index([1, 3, 7, 2, 5])\\nprint(result)', 'output': '2'}}\n",
      "---NO CODE EXECUTION FAILURES---\n",
      "---DECISION: Code Worked. Run Test cases---\n",
      "{'code_generation': AIMessage(content='{\\n  \"description\": \"This function finds the index of the maximum value in a list.\",\\n  \"imports\": \"None\",\\n  \"code\": \"def find_max_index(lst):\\\\n    if not lst:\\\\n        return -1\\\\n    max_index = 0\\\\n    for i in range(1, len(lst)):\\\\n        if lst[i] > lst[max_index]:\\\\n            max_index = i\\\\n    return max_index\",\\n  \"test\": {\\n    \"input\": \"result = find_max_index([1, 3, 7, 2, 5])\\\\nprint(result)\",\\n    \"output\": \"2\"\\n  }\\n}', response_metadata={'token_usage': {'completion_tokens': 138, 'prompt_tokens': 502, 'total_tokens': 640}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_f4e629d0a5', 'finish_reason': 'stop', 'logprobs': None}, id='run-30d560cf-7652-4dbd-85e5-1a025b53e335-0'), 'error': 'no', 'messages': [HumanMessage(content='Write a Python program that finds the index of the maximum value in a list.', id='f5b4b05d-decd-43dd-b723-4dcc973f6abb'), AIMessage(content=\"Here is my attempt to solve the problem: This function finds the index of the maximum value in a list. \\n Imports: None \\n Code: def find_max_index(lst):\\n    if not lst:\\n        return -1\\n    max_index = 0\\n    for i in range(1, len(lst)):\\n        if lst[i] > lst[max_index]:\\n            max_index = i\\n    return max_index. The test case I shared are \\n Test Case: {'input': 'result = find_max_index([1, 3, 7, 2, 5])\\\\nprint(result)', 'output': '2'}\", id='68f9518b-e95d-42ec-9c81-a81921166d3c'), AIMessage(content=\"Here is my attempt to solve the problem: This function finds the index of the maximum value in a list. \\n Imports: None \\n Code: def find_max_index(lst):\\n    if not lst:\\n        return -1\\n    max_index = 0\\n    for i in range(1, len(lst)):\\n        if lst[i] > lst[max_index]:\\n            max_index = i\\n    return max_index. The test case I shared are \\n Test Case: {'input': 'result = find_max_index([1, 3, 7, 2, 5])\\\\nprint(result)', 'output': '2'}\", id='00707d2c-83d0-4635-bb1f-06368e1f8c05')], 'iterations': 1}\n",
      "----CHECKING TEST CASES---------\n",
      "TEST CASE CHECK - PASSED!\n",
      "---DECISION: FINISH---\n",
      "{'code_generation': AIMessage(content='{\\n  \"description\": \"This function finds the index of the maximum value in a list.\",\\n  \"imports\": \"None\",\\n  \"code\": \"def find_max_index(lst):\\\\n    if not lst:\\\\n        return -1\\\\n    max_index = 0\\\\n    for i in range(1, len(lst)):\\\\n        if lst[i] > lst[max_index]:\\\\n            max_index = i\\\\n    return max_index\",\\n  \"test\": {\\n    \"input\": \"result = find_max_index([1, 3, 7, 2, 5])\\\\nprint(result)\",\\n    \"output\": \"2\"\\n  }\\n}', response_metadata={'token_usage': {'completion_tokens': 138, 'prompt_tokens': 502, 'total_tokens': 640}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_f4e629d0a5', 'finish_reason': 'stop', 'logprobs': None}, id='run-30d560cf-7652-4dbd-85e5-1a025b53e335-0'), 'error': 'no', 'messages': [HumanMessage(content='Write a Python program that finds the index of the maximum value in a list.', id='f5b4b05d-decd-43dd-b723-4dcc973f6abb'), AIMessage(content=\"Here is my attempt to solve the problem: This function finds the index of the maximum value in a list. \\n Imports: None \\n Code: def find_max_index(lst):\\n    if not lst:\\n        return -1\\n    max_index = 0\\n    for i in range(1, len(lst)):\\n        if lst[i] > lst[max_index]:\\n            max_index = i\\n    return max_index. The test case I shared are \\n Test Case: {'input': 'result = find_max_index([1, 3, 7, 2, 5])\\\\nprint(result)', 'output': '2'}\", id='68f9518b-e95d-42ec-9c81-a81921166d3c'), AIMessage(content=\"Here is my attempt to solve the problem: This function finds the index of the maximum value in a list. \\n Imports: None \\n Code: def find_max_index(lst):\\n    if not lst:\\n        return -1\\n    max_index = 0\\n    for i in range(1, len(lst)):\\n        if lst[i] > lst[max_index]:\\n            max_index = i\\n    return max_index. The test case I shared are \\n Test Case: {'input': 'result = find_max_index([1, 3, 7, 2, 5])\\\\nprint(result)', 'output': '2'}\", id='00707d2c-83d0-4635-bb1f-06368e1f8c05')], 'iterations': 1}\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "thread_id = str(uuid.uuid4())\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": thread_id,\n",
    "    }\n",
    "}\n",
    "\n",
    "question = \"Write a Python program that finds the index of the maximum value in a list.\"\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", question)], \"iterations\": 0, \"error\": \"no\"}, config, stream_mode=\"values\"):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 'def find_max_index(lst):\\n'\n",
      "         '    if not lst:\\n'\n",
      "         '        return -1\\n'\n",
      "         '    max_index = 0\\n'\n",
      "         '    for i in range(1, len(lst)):\\n'\n",
      "         '        if lst[i] > lst[max_index]:\\n'\n",
      "         '            max_index = i\\n'\n",
      "         '    return max_index',\n",
      " 'description': 'This function finds the index of the maximum value in a list.',\n",
      " 'imports': 'None',\n",
      " 'test': {'input': 'result = find_max_index([1, 3, 7, 2, 5])\\nprint(result)',\n",
      "          'output': '2'}}\n"
     ]
    }
   ],
   "source": [
    "final_solution = s['code_generation'].content\n",
    "final_solution = json.loads(final_solution)\n",
    "\n",
    "pprint.pprint(final_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': 'no', 'messages': [HumanMessage(content='Write a Python program that takes two strings as input and returns the largest common substring between them.', id='c9681290-5dbf-4965-8bf4-928d09904ebb')], 'iterations': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in LangChainTracer.on_chain_end callback: AttributeError(\"'NoneType' object has no attribute 'append'\")\n",
      "Error in LangChainTracer.on_chain_end callback: AttributeError(\"'NoneType' object has no attribute 'append'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code_generation': AIMessage(content='{\\n  \"description\": \"This function takes two strings as input and returns the largest common substring between them.\",\\n  \"imports\": \"None\",\\n  \"code\": \"def largest_common_substring(str1, str2):\\\\n    m = len(str1)\\\\n    n = len(str2)\\\\n    result = \\'\\'\\\\n    length = 0\\\\n    dp = [[0] * (n + 1) for _ in range(m + 1)]\\\\n\\\\n    for i in range(1, m + 1):\\\\n        for j in range(1, n + 1):\\\\n            if str1[i - 1] == str2[j - 1]:\\\\n                dp[i][j] = dp[i - 1][j - 1] + 1\\\\n                if dp[i][j] > length:\\\\n                    length = dp[i][j]\\\\n                    result = str1[i - length:i]\\\\n            else:\\\\n                dp[i][j] = 0\\\\n    return result\",\\n  \"test\": {\\n    \"input\": \"result = largest_common_substring(\\'abcdef\\', \\'zcdemf\\')\\\\nprint(result)\",\\n    \"output\": \"cde\"\\n  }\\n}', response_metadata={'token_usage': {'completion_tokens': 261, 'prompt_tokens': 634, 'total_tokens': 895}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_f4e629d0a5', 'finish_reason': 'stop', 'logprobs': None}, id='run-b01a5415-33e4-4f9f-bf9a-b9e13a02ee40-0'), 'error': 'no', 'messages': [HumanMessage(content='Write a Python program that takes two strings as input and returns the largest common substring between them.', id='c9681290-5dbf-4965-8bf4-928d09904ebb'), AIMessage(content='Here is my attempt to solve the problem: This function takes two strings as input and returns the largest common substring between them. \\n Imports: None \\n Code: def largest_common_substring(str1, str2):\\n    m = len(str1)\\n    n = len(str2)\\n    result = \\'\\'\\n    length = 0\\n    dp = [[0] * (n + 1) for _ in range(m + 1)]\\n\\n    for i in range(1, m + 1):\\n        for j in range(1, n + 1):\\n            if str1[i - 1] == str2[j - 1]:\\n                dp[i][j] = dp[i - 1][j - 1] + 1\\n                if dp[i][j] > length:\\n                    length = dp[i][j]\\n                    result = str1[i - length:i]\\n            else:\\n                dp[i][j] = 0\\n    return result. The test case I shared are \\n Test Case: {\\'input\\': \"result = largest_common_substring(\\'abcdef\\', \\'zcdemf\\')\\\\nprint(result)\", \\'output\\': \\'cde\\'}', id='da395dc3-e851-4293-9856-6ab376cb4d7a'), AIMessage(content='Here is my attempt to solve the problem: This function takes two strings as input and returns the largest common substring between them. \\n Imports: None \\n Code: def largest_common_substring(str1, str2):\\n    m = len(str1)\\n    n = len(str2)\\n    result = \\'\\'\\n    length = 0\\n    dp = [[0] * (n + 1) for _ in range(m + 1)]\\n\\n    for i in range(1, m + 1):\\n        for j in range(1, n + 1):\\n            if str1[i - 1] == str2[j - 1]:\\n                dp[i][j] = dp[i - 1][j - 1] + 1\\n                if dp[i][j] > length:\\n                    length = dp[i][j]\\n                    result = str1[i - length:i]\\n            else:\\n                dp[i][j] = 0\\n    return result. The test case I shared are \\n Test Case: {\\'input\\': \"result = largest_common_substring(\\'abcdef\\', \\'zcdemf\\')\\\\nprint(result)\", \\'output\\': \\'cde\\'}', id='5427fbe2-3ec4-4170-aba4-c8c1122e3856')], 'iterations': 1}\n",
      "----CHECKING CODE EXECUTION---------\n",
      "Code Solution:  {'description': 'This function takes two strings as input and returns the largest common substring between them.', 'imports': 'None', 'code': \"def largest_common_substring(str1, str2):\\n    m = len(str1)\\n    n = len(str2)\\n    result = ''\\n    length = 0\\n    dp = [[0] * (n + 1) for _ in range(m + 1)]\\n\\n    for i in range(1, m + 1):\\n        for j in range(1, n + 1):\\n            if str1[i - 1] == str2[j - 1]:\\n                dp[i][j] = dp[i - 1][j - 1] + 1\\n                if dp[i][j] > length:\\n                    length = dp[i][j]\\n                    result = str1[i - length:i]\\n            else:\\n                dp[i][j] = 0\\n    return result\", 'test': {'input': \"result = largest_common_substring('abcdef', 'zcdemf')\\nprint(result)\", 'output': 'cde'}}\n",
      "---NO CODE EXECUTION FAILURES---\n",
      "---DECISION: Code Worked. Run Test cases---\n",
      "{'code_generation': AIMessage(content='{\\n  \"description\": \"This function takes two strings as input and returns the largest common substring between them.\",\\n  \"imports\": \"None\",\\n  \"code\": \"def largest_common_substring(str1, str2):\\\\n    m = len(str1)\\\\n    n = len(str2)\\\\n    result = \\'\\'\\\\n    length = 0\\\\n    dp = [[0] * (n + 1) for _ in range(m + 1)]\\\\n\\\\n    for i in range(1, m + 1):\\\\n        for j in range(1, n + 1):\\\\n            if str1[i - 1] == str2[j - 1]:\\\\n                dp[i][j] = dp[i - 1][j - 1] + 1\\\\n                if dp[i][j] > length:\\\\n                    length = dp[i][j]\\\\n                    result = str1[i - length:i]\\\\n            else:\\\\n                dp[i][j] = 0\\\\n    return result\",\\n  \"test\": {\\n    \"input\": \"result = largest_common_substring(\\'abcdef\\', \\'zcdemf\\')\\\\nprint(result)\",\\n    \"output\": \"cde\"\\n  }\\n}', response_metadata={'token_usage': {'completion_tokens': 261, 'prompt_tokens': 634, 'total_tokens': 895}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_f4e629d0a5', 'finish_reason': 'stop', 'logprobs': None}, id='run-b01a5415-33e4-4f9f-bf9a-b9e13a02ee40-0'), 'error': 'no', 'messages': [HumanMessage(content='Write a Python program that takes two strings as input and returns the largest common substring between them.', id='c9681290-5dbf-4965-8bf4-928d09904ebb'), AIMessage(content='Here is my attempt to solve the problem: This function takes two strings as input and returns the largest common substring between them. \\n Imports: None \\n Code: def largest_common_substring(str1, str2):\\n    m = len(str1)\\n    n = len(str2)\\n    result = \\'\\'\\n    length = 0\\n    dp = [[0] * (n + 1) for _ in range(m + 1)]\\n\\n    for i in range(1, m + 1):\\n        for j in range(1, n + 1):\\n            if str1[i - 1] == str2[j - 1]:\\n                dp[i][j] = dp[i - 1][j - 1] + 1\\n                if dp[i][j] > length:\\n                    length = dp[i][j]\\n                    result = str1[i - length:i]\\n            else:\\n                dp[i][j] = 0\\n    return result. The test case I shared are \\n Test Case: {\\'input\\': \"result = largest_common_substring(\\'abcdef\\', \\'zcdemf\\')\\\\nprint(result)\", \\'output\\': \\'cde\\'}', id='da395dc3-e851-4293-9856-6ab376cb4d7a'), AIMessage(content='Here is my attempt to solve the problem: This function takes two strings as input and returns the largest common substring between them. \\n Imports: None \\n Code: def largest_common_substring(str1, str2):\\n    m = len(str1)\\n    n = len(str2)\\n    result = \\'\\'\\n    length = 0\\n    dp = [[0] * (n + 1) for _ in range(m + 1)]\\n\\n    for i in range(1, m + 1):\\n        for j in range(1, n + 1):\\n            if str1[i - 1] == str2[j - 1]:\\n                dp[i][j] = dp[i - 1][j - 1] + 1\\n                if dp[i][j] > length:\\n                    length = dp[i][j]\\n                    result = str1[i - length:i]\\n            else:\\n                dp[i][j] = 0\\n    return result. The test case I shared are \\n Test Case: {\\'input\\': \"result = largest_common_substring(\\'abcdef\\', \\'zcdemf\\')\\\\nprint(result)\", \\'output\\': \\'cde\\'}', id='5427fbe2-3ec4-4170-aba4-c8c1122e3856')], 'iterations': 1}\n",
      "----CHECKING TEST CASES---------\n",
      "TEST CASE CHECK - PASSED!\n",
      "---DECISION: FINISH---\n",
      "{'code_generation': AIMessage(content='{\\n  \"description\": \"This function takes two strings as input and returns the largest common substring between them.\",\\n  \"imports\": \"None\",\\n  \"code\": \"def largest_common_substring(str1, str2):\\\\n    m = len(str1)\\\\n    n = len(str2)\\\\n    result = \\'\\'\\\\n    length = 0\\\\n    dp = [[0] * (n + 1) for _ in range(m + 1)]\\\\n\\\\n    for i in range(1, m + 1):\\\\n        for j in range(1, n + 1):\\\\n            if str1[i - 1] == str2[j - 1]:\\\\n                dp[i][j] = dp[i - 1][j - 1] + 1\\\\n                if dp[i][j] > length:\\\\n                    length = dp[i][j]\\\\n                    result = str1[i - length:i]\\\\n            else:\\\\n                dp[i][j] = 0\\\\n    return result\",\\n  \"test\": {\\n    \"input\": \"result = largest_common_substring(\\'abcdef\\', \\'zcdemf\\')\\\\nprint(result)\",\\n    \"output\": \"cde\"\\n  }\\n}', response_metadata={'token_usage': {'completion_tokens': 261, 'prompt_tokens': 634, 'total_tokens': 895}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_f4e629d0a5', 'finish_reason': 'stop', 'logprobs': None}, id='run-b01a5415-33e4-4f9f-bf9a-b9e13a02ee40-0'), 'error': 'no', 'messages': [HumanMessage(content='Write a Python program that takes two strings as input and returns the largest common substring between them.', id='c9681290-5dbf-4965-8bf4-928d09904ebb'), AIMessage(content='Here is my attempt to solve the problem: This function takes two strings as input and returns the largest common substring between them. \\n Imports: None \\n Code: def largest_common_substring(str1, str2):\\n    m = len(str1)\\n    n = len(str2)\\n    result = \\'\\'\\n    length = 0\\n    dp = [[0] * (n + 1) for _ in range(m + 1)]\\n\\n    for i in range(1, m + 1):\\n        for j in range(1, n + 1):\\n            if str1[i - 1] == str2[j - 1]:\\n                dp[i][j] = dp[i - 1][j - 1] + 1\\n                if dp[i][j] > length:\\n                    length = dp[i][j]\\n                    result = str1[i - length:i]\\n            else:\\n                dp[i][j] = 0\\n    return result. The test case I shared are \\n Test Case: {\\'input\\': \"result = largest_common_substring(\\'abcdef\\', \\'zcdemf\\')\\\\nprint(result)\", \\'output\\': \\'cde\\'}', id='da395dc3-e851-4293-9856-6ab376cb4d7a'), AIMessage(content='Here is my attempt to solve the problem: This function takes two strings as input and returns the largest common substring between them. \\n Imports: None \\n Code: def largest_common_substring(str1, str2):\\n    m = len(str1)\\n    n = len(str2)\\n    result = \\'\\'\\n    length = 0\\n    dp = [[0] * (n + 1) for _ in range(m + 1)]\\n\\n    for i in range(1, m + 1):\\n        for j in range(1, n + 1):\\n            if str1[i - 1] == str2[j - 1]:\\n                dp[i][j] = dp[i - 1][j - 1] + 1\\n                if dp[i][j] > length:\\n                    length = dp[i][j]\\n                    result = str1[i - length:i]\\n            else:\\n                dp[i][j] = 0\\n    return result. The test case I shared are \\n Test Case: {\\'input\\': \"result = largest_common_substring(\\'abcdef\\', \\'zcdemf\\')\\\\nprint(result)\", \\'output\\': \\'cde\\'}', id='5427fbe2-3ec4-4170-aba4-c8c1122e3856')], 'iterations': 1}\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "thread_id = str(uuid.uuid4())\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": thread_id,\n",
    "    }\n",
    "}\n",
    "\n",
    "question = \"Write a Python program that takes two strings as input and returns the largest common substring between them.\"\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", question)], \"iterations\": 0, \"error\": \"no\"}, config, stream_mode=\"values\"):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 'def largest_common_substring(str1, str2):\\n'\n",
      "         '    m = len(str1)\\n'\n",
      "         '    n = len(str2)\\n'\n",
      "         \"    result = ''\\n\"\n",
      "         '    length = 0\\n'\n",
      "         '    dp = [[0] * (n + 1) for _ in range(m + 1)]\\n'\n",
      "         '\\n'\n",
      "         '    for i in range(1, m + 1):\\n'\n",
      "         '        for j in range(1, n + 1):\\n'\n",
      "         '            if str1[i - 1] == str2[j - 1]:\\n'\n",
      "         '                dp[i][j] = dp[i - 1][j - 1] + 1\\n'\n",
      "         '                if dp[i][j] > length:\\n'\n",
      "         '                    length = dp[i][j]\\n'\n",
      "         '                    result = str1[i - length:i]\\n'\n",
      "         '            else:\\n'\n",
      "         '                dp[i][j] = 0\\n'\n",
      "         '    return result',\n",
      " 'description': 'This function takes two strings as input and returns the '\n",
      "                'largest common substring between them.',\n",
      " 'imports': 'None',\n",
      " 'test': {'input': \"result = largest_common_substring('abcdef', 'zcdemf')\\n\"\n",
      "                   'print(result)',\n",
      "          'output': 'cde'}}\n"
     ]
    }
   ],
   "source": [
    "final_solution = s['code_generation'].content\n",
    "final_solution = json.loads(final_solution)\n",
    "\n",
    "pprint.pprint(final_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
