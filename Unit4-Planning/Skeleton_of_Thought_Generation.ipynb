{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7oT5LEa-c54"
      },
      "source": [
        "## Skeleton of Thought method of generation\n",
        "\n",
        "LLM decoding is normally sequential. In this method of decoding, the LLM first generates a skeleton of the response. Then it elaborates on each point in the skeleton concurrently.\n",
        "\n",
        "This method of decoding resembles how humans approach a problem - First generate the outline of a solution and then do parallel processing\n",
        "\n",
        "You can read more in my blog here: https://generativeai.pub/skeleton-of-thought-processing-0980d9b75f52\n",
        "\n",
        "![skeleton-of-thought-process.png](images/sot.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw3l4YdP_4ga"
      },
      "source": [
        "## Skeleton of thought step by step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zFACeK_v_els"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") ## Put your OpenAI API key here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nCRsDYhJACjY"
      },
      "outputs": [],
      "source": [
        "class Gpt4Turbo:\n",
        "    def __init__(self):\n",
        "        self.MODEL = 'gpt-3.5-turbo'\n",
        "        self.TOKEN_LIMIT=4000\n",
        "        self.client = OpenAI()\n",
        "\n",
        "    def gptCall_json(self, temperature, messages: list):\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(model=self.MODEL,\n",
        "                                                    messages=messages,\n",
        "                                                    temperature=temperature,\n",
        "                                                    max_tokens=self.TOKEN_LIMIT,\n",
        "                                                    stream=False,\n",
        "                                                    response_format={\"type\": \"json_object\"}) ## Enforce output format\n",
        "\n",
        "            output = response.choices[0].message.content\n",
        "            return output\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            return \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdj0dnzqAGxu"
      },
      "source": [
        "## Prompt to generate the skeleon outline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "L5LCRN5ZAGMG"
      },
      "outputs": [],
      "source": [
        "question = \"How can I improve my time management skills?\"\n",
        "outline_prompt = f'''\n",
        "You're an organizer responsible for only giving the skeleton (not the full content) for answering the question.\n",
        "Provide the skeleton as a JSON to answer the question. Instead of writing a full sentence, each skeleton point should\n",
        "be very short with only 2~5 words. Generally, the skeleton should have 3~10 points. The skeleton is an outline that would be expanded later.\n",
        "Don't elaborate on the point in the skeleton.\n",
        "Example:\n",
        "\\n\\nQuestion:\\nWhat are the typical types of Chinese dishes?: \\n Response: {{\"answer\" : [\"Dumplings\" , \"Noodles\" , \"Dim Sum\" , \"Hot Pot\" , \"Wonton\", \"Ma Po Tofu\", \"Char Siu\", \" Fried Rice\"]}}.\n",
        "\\n\\nQuestion:\\nWhat are some practical tips for individuals to reduce their carbon emissions?\\n Response: {{ \"answer\" :[\"Energy Conservation\", \"Efficient transportation\", \"Home Energy Efficiency\", \"Reduce Water Consumption\", \"Sustainable Diet\", \"Sustainable Travel\"]}}\n",
        "\n",
        " \\n\\nNow, please provide the skeleton for the following question.\\n{question}\\n Response: {{\"answer\": [...]}}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ru4OQ7DAO97",
        "outputId": "d201eb1d-51dc-42a8-d1df-62c60ba54657"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Set goals', 'Prioritize tasks', 'Create schedule', 'Use tools', 'Avoid multitasking', 'Take breaks', 'Delegate tasks', 'Learn to say no']\n"
          ]
        }
      ],
      "source": [
        "TEMPERATURE=0.5\n",
        "message=[]\n",
        "\n",
        "message.append({\"role\": \"system\", \"content\": \"You are a helpful assistant. You respond in JSON format.\"})\n",
        "message.append({\"role\": \"user\", \"content\": outline_prompt})\n",
        "\n",
        "\n",
        "final_output = []\n",
        "gpt4_turbo = Gpt4Turbo()\n",
        "result = gpt4_turbo.gptCall_json(TEMPERATURE,message)\n",
        "result = json.loads(result)['answer']\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV-TNK0uAP2u"
      },
      "source": [
        "Nice! So we got the model to five us a skeleton of the output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JW2os7hAAXew"
      },
      "source": [
        "### Prompt to elaborate on a point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "orO6bC4OAPM_"
      },
      "outputs": [],
      "source": [
        "point = result[0]\n",
        "point_prompt = f'''\n",
        "You help elaborate on the point user wants. Your input is a question and one possible answer from the question, also called <point>. You will elaborate on the <point> and give a 2-3 sentence response\n",
        "on how the <point> helps answer the question. Start your response by mentioning the <point> and then colon like point: and then your response\n",
        "Your response will be in JSON format. Example: {{\"answer\": {point}: your response\"}}\n",
        "\\n\\nNow, please elaborate on the following point. Question: {question}\\n <Point> : {point} \\n Response: {{\"answer\": [...]}}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VavyRWFAeP3",
        "outputId": "ce542c10-ee44-4c60-f9e7-3c11db8baf8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"answer\": \"Set goals: Setting clear and achievable goals is essential for improving time management skills. By establishing specific objectives, you can prioritize tasks, allocate time effectively, and track your progress. This helps you stay focused, organized, and motivated to manage your time more efficiently.\"}\n"
          ]
        }
      ],
      "source": [
        "TEMPERATURE=0.3\n",
        "message=[]\n",
        "\n",
        "message.append({\"role\": \"system\", \"content\": \"You are a helpful assistant. You respond in JSON format.\"})\n",
        "message.append({\"role\": \"user\", \"content\": point_prompt})\n",
        "\n",
        "\n",
        "gpt4_turbo = Gpt4Turbo()\n",
        "result = gpt4_turbo.gptCall_json(TEMPERATURE,message)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgBTtu76Ag0K"
      },
      "source": [
        "## Putting both together including concurrent calls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "er3HWOv8Aehk"
      },
      "outputs": [],
      "source": [
        "import concurrent.futures\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Upccbz6rAopt"
      },
      "outputs": [],
      "source": [
        "class Gpt4Turbo:\n",
        "    def __init__(self):\n",
        "        self.MODEL = 'gpt-3.5-turbo-1106'\n",
        "        self.TOKEN_LIMIT=4000\n",
        "        self.client = OpenAI()\n",
        "        self.temperature =0.3\n",
        "        self.streaming = False\n",
        "\n",
        "    def gptCall_json(self, temperature, messages: list):\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(model=self.MODEL,\n",
        "                                                    messages=messages,\n",
        "                                                    temperature=temperature,\n",
        "                                                    max_tokens=self.TOKEN_LIMIT,\n",
        "                                                    stream=False,\n",
        "                                                    response_format={\"type\": \"json_object\"}) ## Enforce output format\n",
        "\n",
        "\n",
        "            return response.choices[0].message.content\n",
        "\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            return \"\"\n",
        "\n",
        "    def generate_skeleton(self):\n",
        "        question = self.question\n",
        "        outline_prompt = f'''\n",
        "        You're an organizer responsible for only giving the skeleton (not the full content) for answering the question.\n",
        "        Provide the skeleton as a JSON to answer the question. Instead of writing a full sentence, each skeleton point should\n",
        "        be very short with only 2~5 words. Generally, the skeleton should have 3~10 points. The skeleton is an outline that would be expanded later.\n",
        "        Don't elaborate on the point in the skeleton.\n",
        "        Example:\n",
        "        \\n\\nQuestion:\\nWhat are the typical types of Chinese dishes?: \\n Response: {{\"answer\" : [\"Dumplings\" , \"Noodles\" , \"Dim Sum\" , \"Hot Pot\" , \"Wonton\", \"Ma Po Tofu\", \"Char Siu\", \" Fried Rice\"]}}.\n",
        "        \\n\\nQuestion:\\nWhat are some practical tips for individuals to reduce their carbon emissions?\\n Response: {{ \"answer\" :[\"Energy Conservation\", \"Efficient transportation\", \"Home Energy Efficiency\", \"Reduce Water Consumption\", \"Sustainable Diet\", \"Sustainable Travel\"]}}\n",
        "\n",
        "        \\n\\nNow, please provide the skeleton for the following question.\\n{question}\\n Response: {{\"answer\": [...]}}\n",
        "        '''\n",
        "\n",
        "        ## Make the message\n",
        "        message=[]\n",
        "        message.append({\"role\": \"system\", \"content\": \"You are a helpful assistant. You respond in JSON format.\"})\n",
        "        message.append({\"role\": \"user\", \"content\": outline_prompt})\n",
        "\n",
        "        result = self.gptCall_json(self.temperature, message)\n",
        "        result = json.loads(result)\n",
        "        self.result = result['answer']\n",
        "\n",
        "\n",
        "    def elaborate_point(self, point):\n",
        "\n",
        "        question = self.question\n",
        "\n",
        "        point_prompt = f'''\n",
        "        You help elaborate on the point user wants. Your input is a question and one possible answer from the question, also called <point>. You will elaborate on the <point> and give a 2-3 sentence response\n",
        "        on how the <point> helps answer the question. Start your response by mentioning the <point> and then colon like point: and then your response\n",
        "        Your response will be in JSON format. Example: {{\"answer\": {point}: your response\"}}\n",
        "        \\n\\nNow, please elaborate on the following point. Question: {question}\\n <Point> : {point} \\n Response: {{\"answer\": [...]}}\n",
        "        '''\n",
        "\n",
        "        ## Make the message\n",
        "        message=[]\n",
        "        message.append({\"role\": \"system\", \"content\": \"You are a helpful assistant. You respond in JSON format.\"})\n",
        "        message.append({\"role\": \"user\", \"content\": point_prompt})\n",
        "\n",
        "        result = self.gptCall_json(self.temperature, message)\n",
        "        point_elaborate = json.loads(result)\n",
        "        return point_elaborate['answer']\n",
        "\n",
        "\n",
        "    def concurrent_results(self, question):\n",
        "        self.question = question\n",
        "        self.generate_skeleton()\n",
        "        num_points = len(self.result)\n",
        "        # Create a thread pool executor with 5 threads\n",
        "        with concurrent.futures.ThreadPoolExecutor(max_workers=num_points) as executor:\n",
        "            # Submit the API calls to the executor\n",
        "            outputs = [executor.submit(self.elaborate_point, point) for point in self.result]\n",
        "            # Wait for the API calls to complete and get the results\n",
        "            results = [future.result() for future in concurrent.futures.as_completed(outputs)]\n",
        "\n",
        "        # Use list comprehension to add enumeration and \"\\n\" each record\n",
        "        string_list = [f\"{i+1}. {record}\\n\" for i, record in enumerate(results)]\n",
        "\n",
        "        # Join the string_list elements into a single string\n",
        "        final_output = ''.join(string_list)\n",
        "        return final_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukvdqitZArcf",
        "outputId": "ef451e22-1738-428e-b3c5-feda498a6ce0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Set goals: Setting goals helps you prioritize your tasks and allocate your time effectively. By defining clear objectives, you can focus on activities that align with your goals and avoid wasting time on less important tasks. This allows you to manage your time more efficiently and achieve better results.\n",
            "2. Delegate when possible: Delegating tasks to others can help free up your time to focus on more important or high-priority tasks. By assigning tasks to others who are capable, you can ensure that work is being completed efficiently and effectively, allowing you to better manage your time and workload.\n",
            "3. Take breaks: Taking breaks can help improve productivity and focus by allowing the brain to rest and recharge. It can also prevent burnout and help maintain a healthy work-life balance, ultimately leading to better time management.\n",
            "4. Limit distractions: By limiting distractions, you can create a focused environment that allows you to allocate your time more effectively. This helps in managing time by reducing interruptions and increasing productivity, enabling you to complete tasks more efficiently.\n",
            "5. Time blocking: Time blocking is a time management technique where you schedule specific blocks of time for different tasks or activities. This helps you focus on one task at a time, reduces multitasking, and allows for better prioritization of important activities. By allocating dedicated time slots for different tasks, you can effectively manage your time and improve productivity.\n",
            "6. Use tools and technology: By leveraging tools and technology such as time management apps, calendars, and project management software, you can streamline your tasks, set reminders, and prioritize your activities. This can help you stay organized, track your progress, and make more efficient use of your time.\n",
            "7. Reflect and adjust: Reflecting on how you currently manage your time and identifying areas for improvement allows you to make necessary adjustments. By evaluating your current time management strategies and making changes based on your reflections, you can continuously improve your approach to managing time effectively.\n",
            "8. Prioritize tasks: Prioritizing tasks helps you focus on the most important and urgent activities, allowing you to allocate your time and resources efficiently. By identifying and tackling high-priority tasks first, you can ensure that you make the most significant impact on your goals and overall productivity.\n",
            "\n",
            "CPU times: user 77.3 ms, sys: 9.34 ms, total: 86.7 ms\n",
            "Wall time: 2.46 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "gpt4_turbo = Gpt4Turbo()\n",
        "question = \"How do I best manage my time?\"\n",
        "result_sot = gpt4_turbo.concurrent_results(question)\n",
        "print(result_sot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt8Zw_zEBOjC",
        "outputId": "cf244668-a8be-4bed-8369-5408341e17e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of tokens: 444\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "num_tokens = len(encoding.encode(result_sot))\n",
        "print(f\"Number of tokens: {num_tokens}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNdeIf_QA7iU"
      },
      "source": [
        "It took 2.2s to generate an output that was 360 tokens\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_4g9VEjlFX8"
      },
      "source": [
        "### General ChatGPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afRAzt56A6o1",
        "outputId": "db290bee-0eaf-4f99-b18c-e59848e775a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'tips': ['Prioritize your tasks by importance and deadline to ensure you focus on the most critical ones first', 'Create a daily or weekly schedule to allocate specific time slots for different activities or projects', 'Use time management tools such as calendars, to-do lists, or apps to help you stay organized and on track', 'Break down larger tasks into smaller, manageable steps to avoid feeling overwhelmed and to make progress more achievable', 'Minimize distractions by setting specific periods for focused work and taking regular breaks to maintain productivity', 'Learn to say no to non-essential tasks or commitments to avoid overloading your schedule', 'Regularly review and adjust your time management strategies to identify areas for improvement and adapt to changing priorities', 'Consider seeking support or guidance from a mentor, coach, or time management expert to develop personalized strategies for optimizing your time']}\n",
            "CPU times: user 22 ms, sys: 2.84 ms, total: 24.9 ms\n",
            "Wall time: 1.99 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "gpt4_turbo = Gpt4Turbo()\n",
        "\n",
        "message=[]\n",
        "message.append({\"role\": \"system\", \"content\": \"You are a helpful assistant. Respond in JSON format\"})\n",
        "message.append({\"role\": \"user\", \"content\": f'Answer the user question below as a LONG answer of atleast 8 sentences. Give the answer in bullets.  Question: {question}. Answer: {{\"answer\" : ...}}'})\n",
        "\n",
        "single_result = gpt4_turbo.gptCall_json(temperature=0.3, messages=message)\n",
        "single_result = json.loads(single_result)\n",
        "print(single_result['answer'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuMFABpAl92L"
      },
      "source": [
        "It took 1.92 seconds to generate an output that is smaller"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGpTafZYwgSR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
