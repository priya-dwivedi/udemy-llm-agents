{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU02uIts0zQU"
      },
      "source": [
        "### Set your credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import yaml\n",
        "from dotenv import load_dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set Credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8YSqbVwcXBeM"
      },
      "outputs": [],
      "source": [
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") ## Put your OpenAI API key here\n",
        "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\") ## Put your Tavily Search API key here\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\") ## Put your Langsmith API key here\n",
        "os.environ[\"LANGCHAIN_HUB_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\") ## Put your Langsmith API key here\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = 'true' ## Set this as True\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = 'https://api.smith.langchain.com/' ## Set this as: https://api.smith.langchain.com/\n",
        "os.environ[\"LANGCHAIN_HUB_API_URL\"] = 'https://api.hub.langchain.com' ## Set this as : https://api.hub.langchain.com\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = 'llm-agents'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai053z993oT9"
      },
      "source": [
        "## Self Ask with Search Agent\n",
        "\n",
        "This agent breaks down a complex question into a series of simpler questions and uses a search tool to look up answers to the simpler questions in order to answer the original complex question. It's suitable for scenarios where the question is complex and needs to be broken down.\n",
        "\n",
        "This is the source paper for [Self-Ask](https://ofir.io/self-ask.pdf)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LISYHlMJ5WWz"
      },
      "source": [
        "Difference between Chain of Thought and Self Ask\n",
        "\n",
        "![self-ask.png](../Unit1-Foundation_LLM_Agents/selfask.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2obobQ5G4tzE"
      },
      "source": [
        "Let's review [self-ask with search](https://python.langchain.com/docs/modules/agents/agent_types/self_ask_with_search) as it's defined in Langchain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QH0GCKgcAf5O"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools.tavily_search import TavilyAnswer\n",
        "from langchain.agents import AgentExecutor, create_self_ask_with_search_agent\n",
        "from langchain_community.tools.tavily_search import TavilyAnswer\n",
        "from langchain import hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "Z1Tv2Qqr5dVb",
        "outputId": "445e2367-2efc-4e6f-c20e-938b5d3293c5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Question: Who lived longer, Muhammad Ali or Alan Turing?\\nAre follow up questions needed here: Yes.\\nFollow up: How old was Muhammad Ali when he died?\\nIntermediate answer: Muhammad Ali was 74 years old when he died.\\nFollow up: How old was Alan Turing when he died?\\nIntermediate answer: Alan Turing was 41 years old when he died.\\nSo the final answer is: Muhammad Ali\\n\\nQuestion: When was the founder of craigslist born?\\nAre follow up questions needed here: Yes.\\nFollow up: Who was the founder of craigslist?\\nIntermediate answer: Craigslist was founded by Craig Newmark.\\nFollow up: When was Craig Newmark born?\\nIntermediate answer: Craig Newmark was born on December 6, 1952.\\nSo the final answer is: December 6, 1952\\n\\nQuestion: Who was the maternal grandfather of George Washington?\\nAre follow up questions needed here: Yes.\\nFollow up: Who was the mother of George Washington?\\nIntermediate answer: The mother of George Washington was Mary Ball Washington.\\nFollow up: Who was the father of Mary Ball Washington?\\nIntermediate answer: The father of Mary Ball Washington was Joseph Ball.\\nSo the final answer is: Joseph Ball\\n\\nQuestion: Are both the directors of Jaws and Casino Royale from the same country?\\nAre follow up questions needed here: Yes.\\nFollow up: Who is the director of Jaws?\\nIntermediate answer: The director of Jaws is Steven Spielberg.\\nFollow up: Where is Steven Spielberg from?\\nIntermediate answer: The United States.\\nFollow up: Who is the director of Casino Royale?\\nIntermediate answer: The director of Casino Royale is Martin Campbell.\\nFollow up: Where is Martin Campbell from?\\nIntermediate answer: New Zealand.\\nSo the final answer is: No\\n\\nQuestion: {input}\\nAre followup questions needed here:{agent_scratchpad}'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the prompt to use - you can modify this!\n",
        "prompt = hub.pull(\"hwchase17/self-ask-with-search\")\n",
        "prompt.template"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGuwxTytAKMc"
      },
      "source": [
        "### Set up your LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pClvcR0d5vuB"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(model='gpt-3.5-turbo-0125',\n",
        "                 temperature=0.3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9bGYfDI__7x"
      },
      "source": [
        "### Set up your Search Tools\n",
        "\n",
        "We will initialize the tools we want to use. This is a good tool because it gives us answers (not documents)\n",
        "\n",
        "For this agent, only one tool can be used and it needs to be named “Intermediate Answer”"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "brhV4mXsAA7a"
      },
      "outputs": [],
      "source": [
        "tools = [TavilyAnswer(max_results=1, name=\"Intermediate Answer\")]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QhopqtBAapV"
      },
      "source": [
        "### Setup and run your agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXFBflQhDN62"
      },
      "source": [
        "![agent-steps](../Unit1-Foundation_LLM_Agents/key-agent-steps-first-agent.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "B0fSgBQaAZky"
      },
      "outputs": [],
      "source": [
        "# Construct the Self Ask With Search Agent\n",
        "agent = create_self_ask_with_search_agent(llm, tools, prompt)\n",
        "\n",
        "# Create an agent executor by passing in the agent and tools\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE_e96UMAsmb",
        "outputId": "733cec53-834a-4366-80a9-d38b9dcfb0b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mCould not parse output: Yes.\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mFollow up: Who is the founder of Anthropic?\u001b[0m\u001b[36;1m\u001b[1;3mDario Amodei is the founder of Anthropic, a company established in 2021 by former senior members of OpenAI.\u001b[0m\u001b[32;1m\u001b[1;3mFollow up: When was Dario Amodei born?\u001b[0m\u001b[36;1m\u001b[1;3mDario Amodei was born in 1983.\u001b[0m\u001b[32;1m\u001b[1;3mSo the final answer is: 1983\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'Which year was the founder of Anthropic born in?', 'output': '1983'}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_executor.invoke(\n",
        "    {\"input\": \"Which year was the founder of Anthropic born in?\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24xNM35KEGyT",
        "outputId": "b54b4094-90eb-4733-bb71-72d4a48889ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mYes. \n",
            "Follow up: When was superconductivity discovered?\u001b[0m\u001b[36;1m\u001b[1;3mSuperconductivity was discovered in the conventional sense during the 1950s through the development of two significant theories: the phenomenological Ginzburg–Landau theory in 1950 and the microscopic BCS theory in 1957.\u001b[0m\u001b[32;1m\u001b[1;3mFollow up: Who was the president of the US during the 1950s?\u001b[0m\u001b[36;1m\u001b[1;3mHarry Truman was the president of the United States during the 1950s, specifically from 1950 to 1952.\u001b[0m\u001b[32;1m\u001b[1;3mSo the final answer is: Harry Truman\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'Who was the president of US when superconductivity were discovered?',\n",
              " 'output': 'Harry Truman'}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_executor.invoke(\n",
        "    {\"input\": \"Who was the president of US when superconductivity were discovered?\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9j5NgtHAtmg",
        "outputId": "2cebcf88-636c-49f5-a0c7-e1061e13bf59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mCould not parse output: No.\u001b[0mInvalid or incomplete response\u001b[32;1m\u001b[1;3mFollow up: Which is the highest mountain in Asia?\u001b[0m\u001b[36;1m\u001b[1;3mMount Everest is the highest mountain in Asia, reaching an elevation of 29,032 feet (8,849 meters).\u001b[0m\u001b[32;1m\u001b[1;3mSo the final answer is: Mount Everest\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'I want to hike the highest mountain in Asia. How long does will it take me to hike it?',\n",
              " 'output': 'Mount Everest'}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_executor.invoke(\n",
        "    {\"input\": \"I want to hike the highest mountain in Asia. How long does will it take me to hike it?\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise\n",
        "\n",
        "- Test out the self-ask-with-search agent on your own questions\n",
        "- Where does it work, where does it fail?\n",
        "- What are the limitations of this approach?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
